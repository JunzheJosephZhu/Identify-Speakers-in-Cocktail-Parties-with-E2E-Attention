{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import glob\n",
    "from lxml.html import parse\n",
    "from sphfile import SPHFile\n",
    "import pydub\n",
    "import audiosegment\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.func(x)\n",
    "sr = 16000\n",
    "dropout = 0.3\n",
    "half = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 3\n",
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.971525 -52.028473 (1, 200, 256)\n",
      "['andrea_arsenault', 'brian_lamb', 'csp_waj_susan', 'david_brancaccio', 'eddie_mair', 'joie_chen', 'kathleen_kennedy', 'leon_harris', 'linda_wertheimer', 'linden_soles', 'lisa_mullins', 'lou_waters', 'lynn_vaughan', 'mark_mullen', 'natalie_allen', 'noah_adams', 'peter_jennings', 'robert_siegel', 'ted_koppel', 'thalia_assuras']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class OverlayDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv, compute_original = False):\n",
    "        super().__init__()\n",
    "        self.overlays = pd.read_csv(csv)\n",
    "        self.speakers = list(set(self.overlays['first_speaker']).union(set(self.overlays['second_speaker'])))\n",
    "        self.speakers.sort()\n",
    "        self.spkr2idx = {spkr:i for i, spkr in enumerate(self.speakers)}\n",
    "        self.compute_original = compute_original\n",
    "    def __len__(self):\n",
    "        return len(self.overlays)\n",
    "    def __getitem__(self, idx):\n",
    "        overlay = self.overlays.iloc[idx]\n",
    "        first_segment = np.load(overlay['first_file'])/(2**15)\n",
    "        second_segment = np.load(overlay['second_file'])/(2**15)\n",
    "        #padding to compensate rounding errors\n",
    "        if len(first_segment)>len(second_segment):\n",
    "            padding = np.zeros(len(first_segment)-len(second_segment))\n",
    "            second_segment = np.concatenate((second_segment, padding))\n",
    "        \n",
    "        if len(first_segment)<len(second_segment):\n",
    "            padding = np.zeros(len(second_segment)-len(first_segment))\n",
    "            first_segment = np.concatenate((first_segment, padding))\n",
    "        \n",
    "        \n",
    "        first_idx  = self.spkr2idx[overlay['first_speaker']]\n",
    "        second_idx = self.spkr2idx[overlay['second_speaker']]\n",
    "        target = np.zeros(len(self.speakers))\n",
    "        target[first_idx] = 1.0\n",
    "        target[second_idx] = 1.0\n",
    "        if self.compute_original:\n",
    "            return self.make_spectrogram(first_segment), self.make_spectrogram(second_segment),\\\n",
    "                self.make_spectrogram(first_segment+second_segment), target\n",
    "        else:\n",
    "            return self.make_spectrogram(first_segment+second_segment), target\n",
    "    def make_spectrogram(self, segment):\n",
    "        segment = segment[50:-50] # make size 200\n",
    "        S = librosa.feature.melspectrogram(segment, n_mels = 256, n_fft = 1024, hop_length = 160) # 32 ms window, 10 ms hop\n",
    "        S_dB = librosa.power_to_db(S).T[None, :, :] # add channel dimension\n",
    "        return S_dB\n",
    "\n",
    "trainset = OverlayDataSet('overlay-train.csv', False)\n",
    "valset = OverlayDataSet('overlay-val.csv', False)\n",
    "testset = OverlayDataSet('overlay-test.csv', False)\n",
    "spec3, target = trainset[0]\n",
    "plt.figure(figsize = (20, 6))\n",
    "if trainset.compute_original:\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(spec1[0].T)\n",
    "    plt.subplot(132)\n",
    "    plt.imshow(spec2[0].T)\n",
    "    plt.subplot(133)\n",
    "    plt.imshow(spec3[0].T)\n",
    "print(spec3.max(), spec3.min(), spec3.shape)\n",
    "print(trainset.speakers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maybe try drastically increasing channel number in residual attention stage to see if it overfits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('bestacc:', 0.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import functools\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.input_channels = input_channels\n",
    "        self.output_channels = output_channels\n",
    "        self.stride = stride\n",
    "        self.bn1 = nn.BatchNorm2d(input_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(input_channels, output_channels, 1, 1, bias = False)\n",
    "        self.bn2 = nn.BatchNorm2d(output_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(output_channels, output_channels, 3, stride, padding = 1, bias = False)\n",
    "        self.bn3 = nn.BatchNorm2d(output_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv3 = nn.Conv2d(output_channels, output_channels, 1, 1, bias = False)\n",
    "        self.conv4 = nn.Conv2d(input_channels, output_channels , 1, stride, bias = False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.bn1(x)\n",
    "        out1 = self.relu(out)\n",
    "        out = self.conv1(out1)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv3(out)\n",
    "        if (self.input_channels != self.output_channels) or (self.stride !=1 ):\n",
    "            residual = self.conv4(out1)\n",
    "        out += residual\n",
    "        return out\n",
    "\n",
    "class AttentionModule_stage1(nn.Module):\n",
    "    # input size is 56*56\n",
    "    def __init__(self, in_channels, out_channels, size1=(200, 128), size2=(100, 64), size3=(50, 32)):\n",
    "        super(AttentionModule_stage1, self).__init__()\n",
    "        self.first_residual_blocks = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.trunk_branches = nn.Sequential(\n",
    "            ResidualBlock(in_channels, out_channels),\n",
    "            ResidualBlock(in_channels, out_channels)\n",
    "         )\n",
    "\n",
    "        self.mpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.softmax1_blocks = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.skip1_connection_residual_block = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.mpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.softmax2_blocks = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.skip2_connection_residual_block = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.mpool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.softmax3_blocks = nn.Sequential(\n",
    "            ResidualBlock(in_channels, out_channels),\n",
    "            ResidualBlock(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "        self.interpolation3 = nn.UpsamplingBilinear2d(size=size3)\n",
    "\n",
    "        self.softmax4_blocks = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.interpolation2 = nn.UpsamplingBilinear2d(size=size2)\n",
    "\n",
    "        self.softmax5_blocks = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.interpolation1 = nn.UpsamplingBilinear2d(size=size1)\n",
    "\n",
    "        self.softmax6_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels , kernel_size = 1, stride = 1, bias = False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels , kernel_size = 1, stride = 1, bias = False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.last_blocks = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #batch_size, nheads, length, n_mels = x.shape\n",
    "        x = self.first_residual_blocks(x)\n",
    "        out_trunk = self.trunk_branches(x)\n",
    "        out_mpool1 = self.mpool1(x) # 100x64\n",
    "        out_softmax1 = self.softmax1_blocks(out_mpool1)\n",
    "        out_skip1_connection = self.skip1_connection_residual_block(out_softmax1)\n",
    "        out_mpool2 = self.mpool2(out_softmax1) # 50x32\n",
    "        out_softmax2 = self.softmax2_blocks(out_mpool2)\n",
    "        out_skip2_connection = self.skip2_connection_residual_block(out_softmax2)\n",
    "        out_mpool3 = self.mpool3(out_softmax2) # 25x16\n",
    "        out_softmax3 = self.softmax3_blocks(out_mpool3) \n",
    "        out_interp3 = self.interpolation3(out_softmax3) + out_softmax2\n",
    "        out = out_interp3 + out_skip2_connection\n",
    "        out_softmax4 = self.softmax4_blocks(out)\n",
    "        out_interp2 = self.interpolation2(out_softmax4) + out_softmax1\n",
    "        out = out_interp2 + out_skip1_connection\n",
    "        out_softmax5 = self.softmax5_blocks(out)\n",
    "        out_interp1 = self.interpolation1(out_softmax5) + out_trunk\n",
    "        out_softmax6 = self.softmax6_blocks(out_interp1)\n",
    "        out = (1 + out_softmax6) * out_trunk\n",
    "        out_last = self.last_blocks(out)\n",
    "        return out_last\n",
    "\n",
    "num_heads = 8 # Residual Attention Channels\n",
    "num_heads_2 = 4 # MHA heads\n",
    "\n",
    "\n",
    "class OverlayNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ln = nn.LayerNorm(256)\n",
    "        self.downsample1 = ResidualBlock(1, num_heads, (1, 2))\n",
    "        self.res_att = AttentionModule_stage1(num_heads, num_heads)  # batch_size * num_heads * L *128\n",
    "        self.downsample2 = nn.Sequential(ResidualBlock(num_heads, num_heads//2),\n",
    "                                        ResidualBlock(num_heads//2, 2),\n",
    "                                        ResidualBlock(2, 2, (1, 2)))\n",
    "        self.reshape =  Lambda(lambda x: x.permute((1, 2, 0, 3))) # L * batch_size * (num_heads*128)\n",
    "        self.lstm = nn.LSTM(64, 32, 2, batch_first = False, bidirectional = True, dropout = dropout) # L * batch_size * 200 * n_hidden\n",
    "        self.mha =  torch.nn.MultiheadAttention(64, num_heads = num_heads_2, dropout=dropout, bias=True, kdim=64, vdim=64) # L * N * 64\n",
    "        self.fc1 = nn.Linear(64, 32)\n",
    "        self.average = Lambda(lambda x: x.mean(dim = 0)) # batch * n_hidden\n",
    "        self.tanh = nn.Tanh()\n",
    "        #self.norm = Lambda(lambda x: torch.nn.functional.normalize(x, p = 2, dim = 1)) # L2 normalize across n_hidden\n",
    "        self.fc2 = nn.Linear(32, 20)\n",
    "        self.softmax = nn.Softmax(1)\n",
    "    def forward(self, X):\n",
    "        X = self.ln(X)\n",
    "        X = self.downsample1(X)\n",
    "        #print('first downsample ', X.shape)\n",
    "        X = self.res_att(X)\n",
    "        #print('residual attention ', X.shape)\n",
    "        X = self.downsample2(X)\n",
    "        #print('second downsample ', X.shape)\n",
    "        X = self.reshape(X)\n",
    "        X1, X2 = X[0], X[1]\n",
    "        X1,_ = self.lstm(X1)\n",
    "        X2,_ = self.lstm(X1)\n",
    "        #print('lstm ', X.shape)\n",
    "        X1,_ = self.mha(X1, X1, X1)\n",
    "        X2,_ = self.mha(X2, X2, X2)\n",
    "        #print('mha ', X.shape)\n",
    "        X1 = self.fc1(X1)\n",
    "        X2 = self.fc1(X2)\n",
    "        #print('dense ', X.shape)\n",
    "        X1 = self.average(X1)\n",
    "        X2 = self.average(X2)\n",
    "        #print('mean ', X.shape)\n",
    "        X1 = self.tanh(X1)\n",
    "        X2 = self.tanh(X2)\n",
    "        X1 = self.fc2(X1)\n",
    "        X2 = self.fc2(X2)\n",
    "        X1 = self.softmax(X1)\n",
    "        X2 = self.softmax(X2)\n",
    "        X = torch.stack([X1,X2], dim=0)\n",
    "        X,_ = torch.max(X, dim=0)\n",
    "        return X\n",
    "    \n",
    "    \n",
    "overnet = OverlayNet().cuda(device)\n",
    "    \n",
    "# tune hidden layers smaller if overfit\n",
    "optimizer = torch.optim.Adam(overnet.parameters(), 0.001)\n",
    "\n",
    "if os.path.exists('models/overnet8.pth'):\n",
    "    print('load model')\n",
    "    checkpoint = torch.load('models/overnet8.pth')\n",
    "    overnet.load_state_dict(checkpoint['model_state_dict'])\n",
    "    try:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    except:\n",
    "        print('cannot load optimizer')\n",
    "    loss = checkpoint['loss']\n",
    "    if 'bestacc' in checkpoint:\n",
    "        bestacc = checkpoint['bestacc']\n",
    "    else:\n",
    "        bestacc = 0.0\n",
    "else:\n",
    "    print('initializing new model')\n",
    "    bestacc = 0.0\n",
    "    \n",
    "if half:\n",
    "    overnet.half()  # convert to half precision\n",
    "    for layer in overnet.modules():\n",
    "        if isinstance(layer, nn.BatchNorm2d):\n",
    "            layer.float()\n",
    "            \n",
    "overnet.train()\n",
    "'bestacc:', bestacc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Also Do metrics on hitting a single person right\n",
    "## Theoretical justification that when reducing number of channels, neural network could learn to pair similar spectrum representations with each other: only pitch lines that are greater than a certain threshold will pass relu and become postivie. Batchnorm makes this effect stronger. Therefore, when two channels represent spectrums of different people, when they are added the output will be nothing if it doesn't pass the relu threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b29c2c404ff24c9b989be51a7f527d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1378.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 0.011 accuracy: 0.966\n",
      "[1,   400] loss: 0.011 accuracy: 0.963\n",
      "[1,   600] loss: 0.011 accuracy: 0.963\n",
      "[1,   800] loss: 0.012 accuracy: 0.961\n",
      "[1,  1000] loss: 0.012 accuracy: 0.963\n",
      "[1,  1200] loss: 0.012 accuracy: 0.960\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c514ab4e304048b0979c6aea4982b82a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=173.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val acc: 0.9194192377495463\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "541b614241fa4cf781a3a82f5da17ee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1378.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,   200] loss: 0.010 accuracy: 0.965\n",
      "[2,   400] loss: 0.011 accuracy: 0.966\n",
      "[2,   600] loss: 0.010 accuracy: 0.968\n",
      "[2,   800] loss: 0.012 accuracy: 0.962\n",
      "[2,  1000] loss: 0.012 accuracy: 0.962\n",
      "[2,  1200] loss: 0.012 accuracy: 0.959\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09b085ea55614ccbb6167ae52c8853d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=173.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val acc: 0.9111615245009075\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c7463fd0ab049ddba547371d747583c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1378.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,   200] loss: 0.010 accuracy: 0.967\n",
      "[3,   400] loss: 0.011 accuracy: 0.963\n",
      "[3,   600] loss: 0.010 accuracy: 0.967\n",
      "[3,   800] loss: 0.012 accuracy: 0.961\n",
      "[3,  1000] loss: 0.012 accuracy: 0.960\n",
      "[3,  1200] loss: 0.011 accuracy: 0.965\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e427aaefa33f4d4895bc4929f0ac5f2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=173.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val acc: 0.9159709618874773\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3832ba00b7e4be0bb35d945e681af70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1378.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,   200] loss: 0.011 accuracy: 0.965\n",
      "[4,   400] loss: 0.010 accuracy: 0.966\n",
      "[4,   600] loss: 0.011 accuracy: 0.962\n",
      "[4,   800] loss: 0.011 accuracy: 0.962\n",
      "[4,  1000] loss: 0.011 accuracy: 0.963\n",
      "[4,  1200] loss: 0.012 accuracy: 0.960\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "141a5ef12412438e93f59a1ffb233732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=173.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val acc: 0.9149727767695099\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74dbc59362b24f2ba9ac6126caa706c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1378.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,   200] loss: 0.010 accuracy: 0.967\n",
      "[5,   400] loss: 0.010 accuracy: 0.966\n",
      "[5,   600] loss: 0.010 accuracy: 0.967\n",
      "[5,   800] loss: 0.011 accuracy: 0.963\n",
      "[5,  1000] loss: 0.011 accuracy: 0.964\n",
      "[5,  1200] loss: 0.012 accuracy: 0.960\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9219acf37524c25bb9fc0fa8399e874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=173.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val acc: 0.9177858439201452\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e26e1e987a949f2ac78bed76bace535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1378.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,   200] loss: 0.009 accuracy: 0.971\n",
      "[6,   400] loss: 0.010 accuracy: 0.965\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ab8f83da122d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0movernet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-10a8372e7a7b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mX2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0;31m#print('lstm ', X.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 559\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    560\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "def find_max2(tensor):\n",
    "    array = tensor.cpu().detach().numpy()\n",
    "    max2 = []\n",
    "    for row in array:\n",
    "        max2.append(np.argsort(row)[::-1][:2])\n",
    "    return np.array(max2)\n",
    "\n",
    "def compute_corrects(tensor1, tensor2):\n",
    "    max_1, max_2 = find_max2(tensor1), find_max2(tensor2)\n",
    "    batch_size = max_1.shape[0]\n",
    "    batch_corrects = 0\n",
    "    for i in range(batch_size):\n",
    "        if Counter(max_1[i])==Counter(max_2[i]):\n",
    "            batch_corrects+=1\n",
    "    return batch_corrects\n",
    "\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, pin_memory = True, num_workers = 16)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True, pin_memory = True, num_workers = 16)\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "for epoch in range(64):\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "    for batch_idx, (spec, target) in enumerate(tqdm(trainloader)):\n",
    "        optimizer.zero_grad()\n",
    "        spec, target = spec.float(), target.float()\n",
    "        if half:\n",
    "            spec, target = spec.half(),target.half()\n",
    "        spec = spec.cuda(device)\n",
    "        target = target.cuda(device)\n",
    "\n",
    "        out = overnet(spec)\n",
    "        loss = criterion(out, target)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(overnet.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "                \n",
    "        running_loss += loss.item()\n",
    "        running_accuracy += compute_corrects(out, target)/batch_size\n",
    "        if batch_idx % 200 == 199:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f accuracy: %.3f' % \n",
    "                  (epoch + 1, batch_idx + 1, running_loss / 200, running_accuracy / 200))\n",
    "            running_loss = 0.0\n",
    "            running_accuracy = 0.0\n",
    "            torch.save({\n",
    "            'model_state_dict': overnet.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss\n",
    "            }, 'models/overnet8.pth')\n",
    "\n",
    "        \n",
    "        \n",
    "    corrects = 0\n",
    "    for batch_idx, (spec, target) in enumerate(tqdm(valloader)):\n",
    "        spec, target = spec.float(), target.float()\n",
    "        if half:\n",
    "            spec, target = spec.half(), target.half()\n",
    "        spec = spec.cuda(device)\n",
    "        target = target.cuda(device)\n",
    "        overnet.eval()\n",
    "        out = overnet(spec) \n",
    "        corrects += compute_corrects(out, target)\n",
    "    print('val acc:', corrects/len(valset))\n",
    "    if corrects/len(valset) > bestacc:\n",
    "        bestacc = corrects/len(valset)\n",
    "        torch.save({\n",
    "        'model_state_dict': overnet.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "        'bestacc': bestacc\n",
    "        }, 'models/best-overnet8.pth')\n",
    "    overnet.train()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4cc004c66aa4743a6072466c2ebd986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=173.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test acc: 0.9155172413793103\n"
     ]
    }
   ],
   "source": [
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True, pin_memory = True, num_workers = 16)\n",
    "        \n",
    "corrects = 0\n",
    "for batch_idx, (spec, target) in enumerate(tqdm(testloader)):\n",
    "    spec, target = spec.float(), target.float()\n",
    "    if half:\n",
    "        spec, target = spec.half(), target.half()\n",
    "    spec = spec.cuda(device)\n",
    "    target = target.cuda(device)\n",
    "    overnet.eval()\n",
    "    out = overnet(spec) \n",
    "    corrects += compute_corrects(out, target)\n",
    "print('test acc:', corrects/len(testset))\n",
    "overnet.train()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
