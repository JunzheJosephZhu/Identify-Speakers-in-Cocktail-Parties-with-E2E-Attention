{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import glob\n",
    "from lxml.html import parse\n",
    "from sphfile import SPHFile\n",
    "import pydub\n",
    "import audiosegment\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.func(x)\n",
    "sr = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = 0.3\n",
    "half = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                                                42492\n",
      "anchor_speaker                                     Chris_Buerry\n",
      "anchor_file         trainfiles/start_segments/a960620_seg11.npy\n",
      "positive_file       trainfiles/start_segments/a960617_seg63.npy\n",
      "negative_speaker                                  Korva_Coleman\n",
      "negative_file       trainfiles/start_segments/j960618aseg11.npy\n",
      "Name: 42492, dtype: object\n",
      "0.1459849669838091\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'rastaplp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ea86c8988632>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchor_segment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mS_dB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrastaplp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchor_segment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive_segment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_segment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelorder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m18\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 32 ms window, 10 ms hop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS_dB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rastaplp' is not defined"
     ]
    }
   ],
   "source": [
    "triplets = pd.read_csv('trainfiles/triplets.csv')\n",
    "#triplets = triplets[triplets['anchor_speaker'] == 'i960711p_anchor2']\n",
    "idx = np.random.randint(0, len(triplets))\n",
    "triplet = triplets.iloc[idx]\n",
    "anchor_segment = np.fromfile(triplet['anchor_file'], dtype = np.int16)/(2**15)\n",
    "positive_segment = np.fromfile(triplet['positive_file'], dtype = np.int16)/(2**15)\n",
    "negative_segment = np.fromfile(triplet['negative_file'], dtype = np.int16)/(2**15)\n",
    "print(triplet)\n",
    "print(anchor_segment.std())\n",
    "\n",
    "S_dB = rastaplp(np.concatenate((anchor_segment, positive_segment, negative_segment)), modelorder = 18) # 32 ms window, 10 ms hop\n",
    "plt.figure(figsize = (20, 30))\n",
    "plt.imshow(S_dB)\n",
    "ipd.Audio(np.concatenate((anchor_segment, positive_segment, negative_segment)), rate = sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = pd.read_csv('trainfiles/pairs.csv')\n",
    "idx = np.random.randint(0, len(pairs))\n",
    "pair = pairs.iloc[idx]\n",
    "first_segment = np.fromfile(pair['first_file'], dtype = np.int16)/(2**15)\n",
    "second_segment = np.fromfile(pair['second_file'], dtype = np.int16)/(2**15)\n",
    "S_dB = rastaplp(np.concatenate((anchor_segment, positive_segment, negative_segment)), modelorder = 18) # 32 ms window, 10 ms hop\n",
    "print(S_dB.shape)\n",
    "plt.figure(figsize = (20, 30))\n",
    "plt.imshow(S_dB)\n",
    "if pair['label']:\n",
    "    print('different')\n",
    "else:\n",
    "    print('same')\n",
    "ipd.Audio(np.concatenate((first_segment, second_segment)), rate = sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3292c186d8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class TripletsDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.triplets = pd.read_csv('trainfiles/triplets.csv')\n",
    "    def __len__(self):\n",
    "        return len(self.triplets)\n",
    "    def get_plp(self, filename):\n",
    "        plp_path = 'plp/'+filename\n",
    "        if os.path.exists(plp_path):\n",
    "            return np.load(plp_path)\n",
    "        else:\n",
    "            seg = np.fromfile(filename, dtype = np.int16)/(2**15)\n",
    "            S_dB = self.make_spectrogram(seg)\n",
    "            np.save(plp_path, S_dB)\n",
    "            return S_dB\n",
    "    def __getitem__(self, idx):\n",
    "        triplet = self.triplets.iloc[idx]\n",
    "        anchor_segment = self.get_plp(triplet['anchor_file'])\n",
    "        positive_segment = self.get_plp(triplet['positive_file'])\n",
    "        negative_segment = self.get_plp(triplet['negative_file'])\n",
    "        return anchor_segment, positive_segment, negative_segment\n",
    "    def make_spectrogram(self, segment):\n",
    "        S_dB = rastaplp(segment, modelorder = 18) # 32 ms window, 10 ms hop\n",
    "        S_dB_d1 = np.diff(S_dB, n = 1, axis = 0)\n",
    "        S_dB_d2 = np.diff(S_dB, n = 2, axis = 0)\n",
    "        return np.concatenate((S_dB, S_dB_d1, S_dB_d2), axis = 0).T # add channel dimension\n",
    "trainset = TripletsDataSet()\n",
    "class PairsDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pairs = pd.read_csv('trainfiles/pairs.csv')\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    def get_plp(self, filename):\n",
    "        plp_path = 'plp/'+filename\n",
    "        if os.path.exists(plp_path):\n",
    "            return np.load(plp_path)\n",
    "        else:\n",
    "            seg = np.fromfile(filename, dtype = np.int16)/(2**15)\n",
    "            S_dB = self.make_spectrogram(seg)\n",
    "            np.save(plp_path, S_dB)\n",
    "            return S_dB\n",
    "    def __getitem__(self, idx):\n",
    "        pair = self.pairs.iloc[idx]\n",
    "        seg1 = self.get_plp(pair['first_file'])\n",
    "        seg2 = self.get_plp(pair['second_file'])\n",
    "        label = pair['label']\n",
    "        return (seg1, seg2), label\n",
    "    def make_spectrogram(self, segment):\n",
    "        S_dB = rastaplp(segment, modelorder = 18) # 32 ms window, 10 ms hop\n",
    "        S_dB_d1 = np.diff(S_dB, n = 1, axis = 0)\n",
    "        S_dB_d2 = np.diff(S_dB, n = 2, axis = 0)\n",
    "        return np.concatenate((S_dB, S_dB_d1, S_dB_d2), axis = 0).T # add channel dimension\n",
    "trainset_cls = PairsDataSet()\n",
    "idx = np.random.randint(len(trainset_cls))\n",
    "plt.imshow(trainset_cls[idx][0][np.random.randint(2)].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal version, slow, maybe try torch jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Spectral_Attention(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(Spectral_Attention, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.cell = nn.LSTM(input_size, hidden_size, num_layers, batch_first = False)\n",
    "        self.attention = nn.Linear(hidden_size*num_layers, input_size) # can replace this with better attention mechanism\n",
    "    def zero_state(self, batch_size):\n",
    "        return (torch.zeros(self.num_layers, batch_size, self.hidden_size).cuda(),\n",
    "                torch.zeros(self.num_layers, batch_size, self.hidden_size).cuda())\n",
    "    def forward(self, X, prev_state = None, mask = None): # X: (sequence length, batch, hidden size)\n",
    "        batch_size = X.shape[1]\n",
    "        if prev_state == None: # if we don't initialize hidden state\n",
    "            prev_state = self.zero_state(batch_size)\n",
    "        if mask == None:\n",
    "            mask = torch.ones(batch_size, self.input_size).cuda()\n",
    "        outputs = []\n",
    "        for t, x in enumerate(X):\n",
    "            x = x*mask\n",
    "            x = x[None, ...] # 1, batch, hidden_size\n",
    "            output, (state_h, state_c) = self.cell(x, prev_state)\n",
    "            prev_state = (state_h, state_c)\n",
    "            state_h = state_h.view(batch_size, -1)\n",
    "            mask = self.attention(state_h)\n",
    "            outputs.append(output)\n",
    "        outputs = torch.cat(outputs, dim = 0)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noncausal version with Residual Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): LSTM(54, 32, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "  (1): Lambda()\n",
       "  (2): Dropout(p=0.3, inplace=False)\n",
       "  (3): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (4): Tanh()\n",
       "  (5): Dropout(p=0.3, inplace=False)\n",
       "  (6): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (7): Tanh()\n",
       "  (8): Lambda()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import functools\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.input_channels = input_channels\n",
    "        self.output_channels = output_channels\n",
    "        self.stride = stride\n",
    "        self.bn1 = nn.BatchNorm2d(input_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(input_channels, output_channels//4, 1, 1, bias = False)\n",
    "        self.bn2 = nn.BatchNorm2d(output_channels//4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(output_channels//4, output_channels//4, 3, stride, padding = 1, bias = False)\n",
    "        self.bn3 = nn.BatchNorm2d(output_channels//4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv3 = nn.Conv2d(output_channels//4, output_channels, 1, 1, bias = False)\n",
    "        self.conv4 = nn.Conv2d(input_channels, output_channels , 1, stride, bias = False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.bn1(x)\n",
    "        out1 = self.relu(out)\n",
    "        out = self.conv1(out1)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv3(out)\n",
    "        if (self.input_channels != self.output_channels) or (self.stride !=1 ):\n",
    "            residual = self.conv4(out1)\n",
    "        out += residual\n",
    "        return out\n",
    "\n",
    "class AttentionModule_stage1(nn.Module):\n",
    "    # input size is 56*56\n",
    "    def __init__(self, in_channels, out_channels, size1=(200, 128), size2=(100, 64), size3=(50, 32)):\n",
    "        super(AttentionModule_stage1, self).__init__()\n",
    "        self.first_residual_blocks = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.trunk_branches = nn.Sequential(\n",
    "            ResidualBlock(in_channels, out_channels),\n",
    "            ResidualBlock(in_channels, out_channels)\n",
    "         )\n",
    "\n",
    "        self.mpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.softmax1_blocks = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.skip1_connection_residual_block = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.mpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.softmax2_blocks = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.skip2_connection_residual_block = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.mpool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.softmax3_blocks = nn.Sequential(\n",
    "            ResidualBlock(in_channels, out_channels),\n",
    "            ResidualBlock(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "        self.interpolation3 = nn.UpsamplingBilinear2d(size=size3)\n",
    "\n",
    "        self.softmax4_blocks = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.interpolation2 = nn.UpsamplingBilinear2d(size=size2)\n",
    "\n",
    "        self.softmax5_blocks = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.interpolation1 = nn.UpsamplingBilinear2d(size=size1)\n",
    "\n",
    "        self.softmax6_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels , kernel_size = 1, stride = 1, bias = False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels , kernel_size = 1, stride = 1, bias = False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.last_blocks = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #batch_size, nheads, length, n_mels = x.shape\n",
    "        x = self.first_residual_blocks(x)\n",
    "        out_trunk = self.trunk_branches(x)\n",
    "        out_mpool1 = self.mpool1(x) # 100x64\n",
    "        out_softmax1 = self.softmax1_blocks(out_mpool1)\n",
    "        out_skip1_connection = self.skip1_connection_residual_block(out_softmax1)\n",
    "        out_mpool2 = self.mpool2(out_softmax1) # 50x32\n",
    "        out_softmax2 = self.softmax2_blocks(out_mpool2)\n",
    "        out_skip2_connection = self.skip2_connection_residual_block(out_softmax2)\n",
    "        out_mpool3 = self.mpool3(out_softmax2) # 25x16\n",
    "        out_softmax3 = self.softmax3_blocks(out_mpool3) \n",
    "        #\n",
    "        out_interp3 = self.interpolation3(out_softmax3) + out_softmax2\n",
    "        # print(out_skip2_connection.data)\n",
    "        # print(out_interp3.data)\n",
    "        out = out_interp3 + out_skip2_connection\n",
    "        out_softmax4 = self.softmax4_blocks(out)\n",
    "        out_interp2 = self.interpolation2(out_softmax4) + out_softmax1\n",
    "        out = out_interp2 + out_skip1_connection\n",
    "        out_softmax5 = self.softmax5_blocks(out)\n",
    "        out_interp1 = self.interpolation1(out_softmax5) + out_trunk\n",
    "        out_softmax6 = self.softmax6_blocks(out_interp1)\n",
    "        out = (1 + out_softmax6) * out_trunk\n",
    "        out_last = self.last_blocks(out)\n",
    "        return out_last\n",
    "\n",
    "num_heads = 4\n",
    "siamese = nn.Sequential(nn.LSTM(54, 32, 3, batch_first = True, bidirectional = True, dropout = dropout), # batch_size * 200 * n_hidden\n",
    "                    Lambda(lambda x: x[0].mean(dim = 1)), # batch * n_hidden\n",
    "                    nn.Dropout(dropout),\n",
    "                    nn.Linear(64, 32),\n",
    "                    nn.Tanh(),\n",
    "                    nn.Dropout(dropout),\n",
    "                    nn.Linear(32, 32),\n",
    "                    nn.Tanh(), # batch * n_embedding\n",
    "                    Lambda(lambda x: torch.nn.functional.normalize(x, 2, 1)) # L2 normalize across n_hidden\n",
    "                    ).cuda()\n",
    "# tune hidden layers smaller if overfit\n",
    "optimizer = torch.optim.Adam(siamese.parameters(), 0.001)\n",
    "\n",
    "\n",
    "#checkpoint = torch.load('models/baseline-siamese.pth')\n",
    "#siamese.load_state_dict(checkpoint['model_state_dict'])\n",
    "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "#loss = checkpoint['loss']\n",
    "if half:\n",
    "    siamese.half()  # convert to half precision\n",
    "    for layer in siamese.modules():\n",
    "        if isinstance(layer, nn.BatchNorm2d):\n",
    "            layer.float()\n",
    "            \n",
    "siamese.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things to try: Maybe add a multi-headed timewise attention to LSTM output? See if it focuses on attack of sounds? Actually, I can pretrain using tanh+averaging, then during classification, apply tanh+concat+MHA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-train embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin = 0.3):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "    def forward(self, anchor, positive, negative, size_average=True):\n",
    "        # anchor - positive shape is batch_size * n_embedding\n",
    "        distance_positive = (anchor - positive).pow(2).sum(1).pow(.5)\n",
    "        distance_negative = (anchor - negative).pow(2).sum(1).pow(.5)\n",
    "        losses = F.relu(distance_positive - distance_negative + self.margin)\n",
    "        return losses.mean() if size_average else losses.sum()\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, pin_memory = True, num_workers = 8)\n",
    "criterion = TripletLoss()\n",
    "\n",
    "lasttime = time.time()\n",
    "for epoch in range(30):\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (X_anchor, X_pos, X_neg) in enumerate(trainloader):\n",
    "        optimizer.zero_grad()\n",
    "        if half:\n",
    "            X_anchor, X_pos, X_neg = X_anchor.half(), X_pos.half(), X_neg.half()\n",
    "        else:\n",
    "            X_anchor, X_pos, X_neg = X_anchor.float(), X_pos.float(), X_neg.float()\n",
    "        X_anchor, X_pos, X_neg = X_anchor.cuda(), X_pos.cuda(), X_neg.cuda()\n",
    "        out_anchor, out_pos, out_neg = siamese(X_anchor), siamese(X_pos), siamese(X_neg)\n",
    "        loss = criterion(out_anchor, out_pos, out_neg)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if batch_idx % 200 == 199:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, batch_idx + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "            torch.save({\n",
    "            'model_state_dict': siamese.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss\n",
    "            }, 'models/baseline-siamese.pth')\n",
    "        #measure time\n",
    "        #print('batch time: ', str(time.time()-lasttime)[:4])\n",
    "        lasttime = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Classifier ##\n",
    "# Add Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (siamese): Sequential(\n",
       "    (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): AttentionModule_stage1(\n",
       "      (first_residual_blocks): ResidualBlock(\n",
       "        (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv4): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (trunk_branches): Sequential(\n",
       "        (0): ResidualBlock(\n",
       "          (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv4): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): ResidualBlock(\n",
       "          (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv4): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (mpool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (softmax1_blocks): ResidualBlock(\n",
       "        (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv4): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (skip1_connection_residual_block): ResidualBlock(\n",
       "        (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv4): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (mpool2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (softmax2_blocks): ResidualBlock(\n",
       "        (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv4): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (skip2_connection_residual_block): ResidualBlock(\n",
       "        (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv4): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (mpool3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (softmax3_blocks): Sequential(\n",
       "        (0): ResidualBlock(\n",
       "          (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv4): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): ResidualBlock(\n",
       "          (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (conv4): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (interpolation3): UpsamplingBilinear2d(size=(50, 32), mode=bilinear)\n",
       "      (softmax4_blocks): ResidualBlock(\n",
       "        (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv4): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (interpolation2): UpsamplingBilinear2d(size=(100, 64), mode=bilinear)\n",
       "      (softmax5_blocks): ResidualBlock(\n",
       "        (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv4): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (interpolation1): UpsamplingBilinear2d(size=(200, 128), mode=bilinear)\n",
       "      (softmax6_blocks): Sequential(\n",
       "        (0): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): Sigmoid()\n",
       "      )\n",
       "      (last_blocks): ResidualBlock(\n",
       "        (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv4): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Lambda()\n",
       "    (5): LSTM(512, 32, num_layers=3, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "    (6): Lambda()\n",
       "    (7): Dropout(p=0.5, inplace=False)\n",
       "    (8): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (9): Tanh()\n",
       "    (10): Dropout(p=0.5, inplace=False)\n",
       "    (11): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (12): Tanh()\n",
       "    (13): Lambda()\n",
       "  )\n",
       "  (fc1): Sequential(\n",
       "    (0): Dropout(p=0.3, inplace=False)\n",
       "    (1): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (fc2): Sequential(\n",
       "    (0): Dropout(p=0.3, inplace=False)\n",
       "    (1): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): Dropout(p=0.3, inplace=False)\n",
       "    (1): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, siamese):\n",
    "        super().__init__()\n",
    "        self.siamese = siamese\n",
    "        self.fc1 = nn.Sequential(nn.Dropout(0.3), nn.Linear(64, 64), nn.ReLU())\n",
    "        self.fc2 = nn.Sequential(nn.Dropout(0.3), nn.Linear(64, 64), nn.ReLU())\n",
    "        self.out = nn.Sequential(nn.Dropout(0.3), nn.Linear(64, 1)) # sigmoid is in loss\n",
    "    def forward(self, x1, x2):\n",
    "        embedding_1 = self.siamese(x1) # batch_size * n_embedding\n",
    "        embedding_2 = self.siamese(x2) # batch_size * n_embedding\n",
    "        x = torch.cat([embedding_1, embedding_2], dim = 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return self.out(x).view(x1.shape[0])\n",
    "\n",
    "cls = Classifier(siamese).cuda()\n",
    "optimizer = torch.optim.Adam(cls.parameters(), 0.001)\n",
    "checkpoint = torch.load('models/baseline-cls.pth')\n",
    "cls.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "loss = checkpoint['loss']\n",
    "if half:\n",
    "    cls.half()  # convert to half precision\n",
    "    for layer in cls.modules():\n",
    "        if isinstance(layer, nn.BatchNorm2d):\n",
    "            cls.float()\n",
    "cls.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 0.273 accuracy: 0.900\n",
      "[1,   400] loss: 0.263 accuracy: 0.903\n",
      "[1,   600] loss: 0.268 accuracy: 0.897\n",
      "[1,   800] loss: 0.269 accuracy: 0.895\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-e3f911793f65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/joseph/.local/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mbias_correction1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mbias_correction2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainloader_cls = torch.utils.data.DataLoader(trainset_cls, batch_size=32, shuffle=True, pin_memory = True, num_workers = 8)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "lasttime = time.time()\n",
    "\n",
    "for epoch in range(30):\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "    for batch_idx, ((X_1, X_2), label) in enumerate(trainloader_cls):\n",
    "        optimizer.zero_grad()\n",
    "        if half:\n",
    "            X_1, X_2 = X_1.half(), X_2.half()\n",
    "        else:\n",
    "            X_1, X_2 = X_1.float(), X_2.float()\n",
    "\n",
    "        X_1, X_2, label = X_1.cuda(), X_2.cuda(), label.cuda()\n",
    "        out = cls(X_1, X_2)\n",
    "        label = label.float()\n",
    "        loss = criterion(out, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_accuracy += sum((out.data.cpu().numpy()>0) == label.data.cpu().numpy())/32\n",
    "        if batch_idx % 200 == 199:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f accuracy: %.3f' % \n",
    "                  (epoch + 1, batch_idx + 1, running_loss / 200, running_accuracy / 200))\n",
    "            running_loss = 0.0\n",
    "            running_accuracy = 0.0\n",
    "            torch.save({\n",
    "            'model_state_dict': cls.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss\n",
    "            }, 'models/baseline-cls.pth')\n",
    "        #measure time\n",
    "        #print('batch time: ', str(time.time()-lasttime)[:4])\n",
    "        lasttime = time.time()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runtime test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.039704322814941406\n",
      "0.0667734146118164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joseph/.local/lib/python3.6/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "# runtime test\n",
    "dummy = nn.Sequential(nn.LSTM(128, 256, 3, batch_first = True, bidirectional=True),\n",
    "                      Lambda(lambda x: x[0].mean(dim = 1)),\n",
    "                      nn.Linear(512, 256),\n",
    "                      nn.Tanh(),\n",
    "                      nn.Linear(256, 128),\n",
    "                      nn.Tanh()\n",
    "                      ).cuda()\n",
    "#siamese = Spectral_Attention(128, 512, 3).cuda()\n",
    "loss = torch.nn.MSELoss(size_average=512, reduce=None, reduction='mean')\n",
    "optim1 = torch.optim.Adam(dummy.parameters())\n",
    "optim2 = torch.optim.Adam(siamese.parameters())\n",
    "target = torch.zeros(1, 128).cuda()\n",
    "\n",
    "begin = time.time()\n",
    "out1 = dummy(X[0])\n",
    "loss1 = loss(out1, target)\n",
    "loss1.backward()\n",
    "optim1.step()\n",
    "print(time.time()-begin)\n",
    "\n",
    "begin = time.time()\n",
    "out2 = siamese(X)\n",
    "loss2 = loss(out2, target)\n",
    "loss2.backward()\n",
    "optim2.step()\n",
    "print(time.time()-begin)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use both TDP and IFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.random((int(1e3), int(1e5))).astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('array.npy', S_dB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = np.load('array.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 298)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plp_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-bebf84fdea4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplp_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plp_path' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
