{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import sys\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from librosa.core import resample\n",
    "EPS = 1e-8\n",
    "\n",
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.func(x)\n",
    "old_sr = 8000\n",
    "new_sr = 8000\n",
    "half = False\n",
    "root = '../'\n",
    "load = True\n",
    "\n",
    "device = 1\n",
    "device_ids = [0, 1, 2, 3]\n",
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f51a0463fd0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_features(segment):\n",
    "    S = librosa.feature.melspectrogram(y=segment, n_fft=512, hop_length=256, n_mels = 40)\n",
    "    #S = librosa.power_to_db(S)\n",
    "    S -= S.mean(axis = 1, keepdims = True)\n",
    "    return S\n",
    "\n",
    "def compute_energy(segment):\n",
    "    E = librosa.feature.rms(segment, frame_length=512, hop_length=256)\n",
    "    return E[0]\n",
    "\n",
    "class OverlayDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv):\n",
    "        super().__init__()\n",
    "        self.segments = pd.read_csv(root+csv)\n",
    "        self.speakers = list(set(self.segments['speaker']))\n",
    "        self.speakers.sort()\n",
    "        self.spkr2idx = {spkr:i for i, spkr in enumerate(self.speakers)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.segments)\n",
    "    def __getitem__(self, idx):\n",
    "        seg1 = self.segments.iloc[idx]\n",
    "        seg2 = self.segments.iloc[np.random.randint(len(self.segments))]\n",
    "        while(seg1['speaker']==seg2['speaker']):\n",
    "            seg2 = self.segments.iloc[np.random.randint(len(self.segments))]\n",
    "        seg3 = self.segments.iloc[np.random.randint(len(self.segments))]\n",
    "        while(seg3['speaker']==seg2['speaker'] or seg3['speaker']==seg1['speaker']):\n",
    "            seg3 = self.segments.iloc[np.random.randint(len(self.segments))]\n",
    "            \n",
    "        sig1 = np.load(root+seg1['segfile'])\n",
    "        sig2 = np.load(root+seg2['segfile'])\n",
    "        sig3 = np.load(root+seg3['segfile'])\n",
    "\n",
    "        E1 = compute_energy(sig1) # [n_frames]\n",
    "        E2 = compute_energy(sig2)\n",
    "        E3 = compute_energy(sig3)\n",
    "\n",
    "        out_vec = np.zeros((len(self.speakers), len(E1))) # [#spkrs, n_frames]\n",
    "        out_vec[self.spkr2idx[seg1['speaker']]] = E1/(E1+E2+E3)\n",
    "        out_vec[self.spkr2idx[seg2['speaker']]] = E2/(E1+E2+E3)\n",
    "        out_vec[self.spkr2idx[seg3['speaker']]] = E2/(E1+E2+E3)\n",
    "\n",
    "        S = make_features(sig1+sig2+sig3)\n",
    "\n",
    "        return S, out_vec\n",
    "\n",
    "\n",
    "#mean, std = compute_mean_std('overlay-train.csv')\n",
    "\n",
    "\n",
    "trainset = OverlayDataSet('train-segments.csv')\n",
    "valset = OverlayDataSet('val-segments.csv')\n",
    "testset = OverlayDataSet('test-segments.csv')\n",
    "features, vec = trainset[5]\n",
    "\n",
    "plt.imshow(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wang2018(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 2, kernel_size = 5, padding=2, dilation=1)\n",
    "        self.bn1 = nn.BatchNorm2d(2)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 2, out_channels = 4, kernel_size = 3, padding=1, dilation=1)\n",
    "        self.bn2 = nn.BatchNorm2d(4)\n",
    "        self.conv3 = nn.Conv2d(in_channels = 4, out_channels = 6, kernel_size = 3, padding=2, dilation=2)\n",
    "        self.bn3 = nn.BatchNorm2d(6)\n",
    "        # [batch_size, 6, 40, 128]\n",
    "        # reshape to : [batch_size, 6*40, 128]\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc = nn.Conv1d(6*40, 512, 11, padding = 5)\n",
    "        self.out = nn.Conv1d(512, 20, 1)\n",
    "        self.softmax = nn.Softmax(dim = 1)\n",
    "        #self.softmax = nn.Sigmoid()\n",
    "    def forward(self, X):\n",
    "        X = X.unsqueeze(dim = 1)\n",
    "        X = self.relu(self.bn1(self.conv1(X)))\n",
    "        X = self.relu(self.bn2(self.conv2(X)))\n",
    "        X = self.relu(self.bn3(self.conv3(X))) # [B, 6, H, W]\n",
    "        X = X.view(X.shape[0], -1, X.shape[-1]) # [B, 6*H, W]\n",
    "        X = self.fc(X) # [B, 512, W]\n",
    "        X = self.relu(X)\n",
    "        X = self.out(X)\n",
    "        X = self.softmax(X)\n",
    "        X = X.clamp(min = 1e-8)\n",
    "        return X\n",
    "    \n",
    "model = Wang2018().cuda(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "if load:\n",
    "    checkpoint = torch.load('models/Wang2018.pth')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max3(tensor):\n",
    "    array = tensor.cpu().detach().numpy()\n",
    "    max3 = []\n",
    "    for row in array:\n",
    "        max3.append(np.argsort(row)[::-1][:3])\n",
    "    return np.array(max3)\n",
    "\n",
    "def post_filter(pred):\n",
    "    # pred: [batch_size, 20, n_frames]\n",
    "    maxprob, _ = torch.max(pred, dim = 1, keepdim = True) # [batch_size, 1, n_frames]\n",
    "    beta = 2\n",
    "    frameweight = maxprob**beta # [batch_size, 1, n_frames]\n",
    "    pred *= frameweight # [batch_size, 20, n_frames]\n",
    "    pred = pred.mean(dim = 2) # [batch_size, 20]\n",
    "    return pred\n",
    "    \n",
    "def compute_corrects(tensor1, tensor2): # tensor 1 is pred[B, 20], tensor 2 is truth[B, 20, n_frmaes]\n",
    "    tensor2 = tensor2.mean(dim=2)\n",
    "    preds, truth = find_max3(tensor1), (tensor2>0).float().cpu().detach().numpy()\n",
    "    batch_size = preds.shape[0]\n",
    "    half_corrects = 0\n",
    "    corrects = 0\n",
    "    for i in range(batch_size):\n",
    "        if sum(truth[i][preds[i]]) >= 1:\n",
    "            half_corrects+=1\n",
    "        if sum(truth[i][preds[i]]) == 3:\n",
    "            corrects+=1\n",
    "    return half_corrects, corrects\n",
    "\n",
    "\n",
    "\n",
    "bce = torch.nn.BCELoss()\n",
    "def focalKLD(pred, target, size_average=True): # hasn't been debugged\n",
    "    # input : [batch_size, 20, n_frames]\n",
    "    # target: [batch_size, 20, n_frames]\n",
    "    alpha = 0.5\n",
    "    lamb = 2\n",
    "    CE = -target * torch.log(pred)# - (1-target) * torch.log(1-pred) # [batch_size, 20, n_frames]\n",
    "    decay = torch.sum(input = ((target>0).float()*pred)**lamb, dim = 1, keepdim = True) # [batch_size, 1, n_frames]\n",
    "    w = 1 + alpha - decay # [batch_size, 1, n_frames]\n",
    "    KLD = torch.mean(CE*w)\n",
    "    return KLD\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a8e88a2c5d42bebdacbf7e02eaa8a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1201.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200]  loss: 0.138 half accuracy: 0.975000 accuracy: 0.102\n",
      "[1,   400]  loss: 0.134 half accuracy: 0.978437 accuracy: 0.100\n",
      "[1,   600]  loss: 0.136 half accuracy: 0.976094 accuracy: 0.106\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, pin_memory = True, num_workers = 16)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True, pin_memory = True, num_workers = 16)\n",
    "\n",
    "criterion = focalKLD\n",
    "\n",
    "for epoch in range(64):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    half_accuracy = 0.0\n",
    "    running_accuracy = 0.0\n",
    "    for batch_idx, (features, target) in enumerate(tqdm(trainloader)):\n",
    "        optimizer.zero_grad()\n",
    "        features, target = features.float().cuda(device), target.float().cuda(device)\n",
    "        pred = model(features)\n",
    "        loss = criterion(pred, target)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred = post_filter(pred)\n",
    "        running_loss += loss.item()\n",
    "        half_accuracy+= compute_corrects(pred, target)[0]/batch_size\n",
    "        running_accuracy += compute_corrects(pred, target)[1]/batch_size\n",
    "\n",
    "        \n",
    "        if batch_idx % 200 == 199:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d]  loss: %.3f half accuracy: %3f accuracy: %.3f' % \n",
    "                  (epoch + 1, batch_idx + 1, running_loss / 200, half_accuracy/200, running_accuracy / 200))\n",
    "            torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': running_loss,\n",
    "            }, 'models/Wang2018.pth')\n",
    "            running_loss = 0.0\n",
    "            half_accuracy = 0.0\n",
    "            running_accuracy = 0.0\n",
    "    \n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    half_accuracy = 0.0\n",
    "    running_accuracy = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (features, target) in enumerate(tqdm(valloader)):\n",
    "            features, target = features.float().cuda(device), target.float().cuda(device)\n",
    "            pred = model(features)\n",
    "            loss = criterion(pred, target)\n",
    "            \n",
    "            pred = post_filter(pred)\n",
    "            running_loss += loss.item()\n",
    "            half_accuracy+= compute_corrects(pred, target)[0]\n",
    "            running_accuracy += compute_corrects(pred, target)[1]\n",
    "\n",
    "        print('val 1/2:', half_accuracy/len(valset), 'val 2/2:', running_accuracy/len(valset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43beeccac2f649928ff2d5d1d46c63f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=153.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test 1/2: 0.9267294310274253 val 2/2: 0.32255423659435123\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74266b91dd4e432a82359aee1d71521f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=153.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test 1/2: 0.9318460908718789 val 2/2: 0.3151862464183381\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c149b91df4743d6be06c011028eb237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=153.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test 1/2: 0.9314367580843226 val 2/2: 0.32214490380679495\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e397f19643a4b4b9227b8b58ca2c436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=153.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test 1/2: 0.9322554236594351 val 2/2: 0.32275890298812937\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde25a0beb384f2c807bb36c0e4b94b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=153.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test 1/2: 0.9287760949652067 val 2/2: 0.3288988948014736\n"
     ]
    }
   ],
   "source": [
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True, pin_memory = True, num_workers = 16)\n",
    "for i in range(5):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        half_accuracy = 0.0\n",
    "        running_accuracy = 0.0\n",
    "        for batch_idx, (features, target) in enumerate(tqdm(testloader)):\n",
    "            features, target = features.float().cuda(device), target.float().cuda(device)\n",
    "            pred = model(features)\n",
    "            loss = criterion(pred, target)\n",
    "            \n",
    "            pred = post_filter(pred)\n",
    "            running_loss += loss.item()\n",
    "            half_accuracy+= compute_corrects(pred, target)[0]\n",
    "            running_accuracy += compute_corrects(pred, target)[1]\n",
    "\n",
    "        print('test 1/2:', half_accuracy/len(testset), 'val 2/2:', running_accuracy/len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_bn() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv1d'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.activation.Softmax'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class '__main__.Wang2018'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "0.146304872 1.362826\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "from thop import profile\n",
    "model.cpu()\n",
    "feature, _ = trainset[0]\n",
    "feature = torch.Tensor(feature[None, ...])\n",
    "macs, params = profile(model, inputs=(feature, ))\n",
    "print(macs/10**9, params/10**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
