{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import glob\n",
    "from lxml.html import parse\n",
    "from sphfile import SPHFile\n",
    "import pydub\n",
    "import audiosegment\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_df = pd.read_csv('trainfiles/start.csv')\n",
    "end_df = pd.read_csv('trainfiles/end.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_df = start_df.append(end_df)\n",
    "speakers = Counter(segments_df['speaker'])\n",
    "common_speakers = speakers.most_common(20)\n",
    "segments_by_speakers = {speaker:segments_df[segments_df['speaker']==speaker] for speaker, count in common_speakers}\n",
    "segments_by_speakers\n",
    "common_speakers = [common_speaker[0] for common_speaker in common_speakers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maybe try increasing dataset size by doing each combination of 290*290"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay = []\n",
    "for first_speaker in common_speakers:\n",
    "    second_speakers = [speaker for speaker in common_speakers if speaker!=first_speaker ]\n",
    "    first_segments = segments_by_speakers[first_speaker]\n",
    "    for second_speaker in second_speakers:\n",
    "        second_segments = segments_by_speakers[second_speaker]\n",
    "        first_idx = np.arange(290)\n",
    "        second_idx = np.arange(290)\n",
    "        np.random.shuffle(first_idx)\n",
    "        np.random.shuffle(second_idx)\n",
    "        for i in range(290):\n",
    "            first_segment = first_segments.iloc[first_idx[i]]\n",
    "            second_segment = second_segments.iloc[second_idx[i]]\n",
    "            row = {'first_speaker': first_speaker, 'second_speaker': second_speaker,\n",
    "                  'first_file': first_segment['segfile'], 'second_file': second_segment['segfile']}\n",
    "            overlay.append(row)\n",
    "overlay = pd.DataFrame(overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_speaker</th>\n",
       "      <th>second_speaker</th>\n",
       "      <th>first_file</th>\n",
       "      <th>second_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60350</th>\n",
       "      <td>eddie_mair</td>\n",
       "      <td>andrea_arsenault</td>\n",
       "      <td>trainfiles/start_segments/eh971016_seg104.npy</td>\n",
       "      <td>trainfiles/end_segments/d960530a_seg0.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107186</th>\n",
       "      <td>andrea_arsenault</td>\n",
       "      <td>brian_lamb</td>\n",
       "      <td>trainfiles/end_segments/d960604a_seg75.npy</td>\n",
       "      <td>trainfiles/start_segments/i960531__seg446.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18671</th>\n",
       "      <td>lou_waters</td>\n",
       "      <td>brian_lamb</td>\n",
       "      <td>trainfiles/start_segments/ee970703_seg41.npy</td>\n",
       "      <td>trainfiles/start_segments/ew970627_seg297.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36889</th>\n",
       "      <td>ted_koppel</td>\n",
       "      <td>mark_mullen</td>\n",
       "      <td>trainfiles/start_segments/a960612__seg77.npy</td>\n",
       "      <td>trainfiles/start_segments/b960606__seg84.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99060</th>\n",
       "      <td>thalia_assuras</td>\n",
       "      <td>andrea_arsenault</td>\n",
       "      <td>trainfiles/start_segments/b960618__seg34.npy</td>\n",
       "      <td>trainfiles/start_segments/d960604a_seg23.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109993</th>\n",
       "      <td>andrea_arsenault</td>\n",
       "      <td>robert_siegel</td>\n",
       "      <td>trainfiles/end_segments/d960515__seg245.npy</td>\n",
       "      <td>trainfiles/start_segments/j960617__seg303.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85412</th>\n",
       "      <td>lynn_vaughan</td>\n",
       "      <td>lisa_mullins</td>\n",
       "      <td>trainfiles/end_segments/f960607b_seg50.npy</td>\n",
       "      <td>trainfiles/start_segments/eh971015_seg58.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2177</th>\n",
       "      <td>peter_jennings</td>\n",
       "      <td>brian_lamb</td>\n",
       "      <td>trainfiles/start_segments/ea980119_seg56.npy</td>\n",
       "      <td>trainfiles/start_segments/i960610__seg188.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77285</th>\n",
       "      <td>mark_mullen</td>\n",
       "      <td>peter_jennings</td>\n",
       "      <td>trainfiles/start_segments/b960613a_seg15.npy</td>\n",
       "      <td>trainfiles/start_segments/c960528__seg21.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86498</th>\n",
       "      <td>lynn_vaughan</td>\n",
       "      <td>leon_harris</td>\n",
       "      <td>trainfiles/start_segments/f960606a_seg52.npy</td>\n",
       "      <td>trainfiles/start_segments/eo970829_seg55.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110200 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           first_speaker    second_speaker  \\\n",
       "60350         eddie_mair  andrea_arsenault   \n",
       "107186  andrea_arsenault        brian_lamb   \n",
       "18671         lou_waters        brian_lamb   \n",
       "36889         ted_koppel       mark_mullen   \n",
       "99060     thalia_assuras  andrea_arsenault   \n",
       "...                  ...               ...   \n",
       "109993  andrea_arsenault     robert_siegel   \n",
       "85412       lynn_vaughan      lisa_mullins   \n",
       "2177      peter_jennings        brian_lamb   \n",
       "77285        mark_mullen    peter_jennings   \n",
       "86498       lynn_vaughan       leon_harris   \n",
       "\n",
       "                                           first_file  \\\n",
       "60350   trainfiles/start_segments/eh971016_seg104.npy   \n",
       "107186     trainfiles/end_segments/d960604a_seg75.npy   \n",
       "18671    trainfiles/start_segments/ee970703_seg41.npy   \n",
       "36889    trainfiles/start_segments/a960612__seg77.npy   \n",
       "99060    trainfiles/start_segments/b960618__seg34.npy   \n",
       "...                                               ...   \n",
       "109993    trainfiles/end_segments/d960515__seg245.npy   \n",
       "85412      trainfiles/end_segments/f960607b_seg50.npy   \n",
       "2177     trainfiles/start_segments/ea980119_seg56.npy   \n",
       "77285    trainfiles/start_segments/b960613a_seg15.npy   \n",
       "86498    trainfiles/start_segments/f960606a_seg52.npy   \n",
       "\n",
       "                                          second_file  \n",
       "60350       trainfiles/end_segments/d960530a_seg0.npy  \n",
       "107186  trainfiles/start_segments/i960531__seg446.npy  \n",
       "18671   trainfiles/start_segments/ew970627_seg297.npy  \n",
       "36889    trainfiles/start_segments/b960606__seg84.npy  \n",
       "99060    trainfiles/start_segments/d960604a_seg23.npy  \n",
       "...                                               ...  \n",
       "109993  trainfiles/start_segments/j960617__seg303.npy  \n",
       "85412    trainfiles/start_segments/eh971015_seg58.npy  \n",
       "2177    trainfiles/start_segments/i960610__seg188.npy  \n",
       "77285    trainfiles/start_segments/c960528__seg21.npy  \n",
       "86498    trainfiles/start_segments/eo970829_seg55.npy  \n",
       "\n",
       "[110200 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlay_shuffled = overlay.sample(frac=1, random_state = 12345)\n",
    "tenth = int(len(overlay)*0.1)\n",
    "overlay_shuffled[:8*tenth].to_csv('overlay-train.csv')\n",
    "overlay_shuffled[8*tenth:9*tenth].to_csv('overlay-val.csv')\n",
    "overlay_shuffled[9*tenth:].to_csv('overlay-test.csv')\n",
    "overlay_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
