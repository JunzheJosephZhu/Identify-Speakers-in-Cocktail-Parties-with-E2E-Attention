{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from librosa.core import resample\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "import torch\n",
    "import pathlib\n",
    "def create_dir(filename):\n",
    "    pathlib.Path('/'.join(filename.split('/')[:-1])).mkdir(parents=True, exist_ok=True)\n",
    "from tqdm.notebook import tqdm\n",
    "sys.path.append('Conv-TasNet/src/')\n",
    "sys.path.append('SincNet/')\n",
    "from conv_tasnet import *\n",
    "from pit_criterion import cal_loss\n",
    "from dnn_models import *\n",
    "from data_io import ReadList,read_conf_inp,str_to_bool\n",
    "from collections import Counter\n",
    "import os\n",
    "device = 3\n",
    "root = '../'\n",
    "old_sr = 16000\n",
    "new_sr = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load8hz(filename):\n",
    "    samples = np.load(filename)/(2**15)\n",
    "    samples = resample(samples, old_sr, new_sr)\n",
    "    # pad the samples\n",
    "    if len(samples)>16000:\n",
    "        samples = samples[:16000]\n",
    "    if len(samples)<16000:\n",
    "        padding = np.zeros(16000-len(samples))\n",
    "        samples = np.concatenate([samples, padding])\n",
    "    \n",
    "    return samples\n",
    "\n",
    "class E2ESet(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, csv):\n",
    "        super().__init__()\n",
    "        self.root = root\n",
    "        self.csv = pd.read_csv(root+csv)\n",
    "        self.speakers = list(set(self.csv['first_speaker']))\n",
    "        self.speakers.sort()\n",
    "        self.spkr2idx = {spkr:i for i, spkr in enumerate(self.speakers)}\n",
    "    def __len__(self):\n",
    "        return len(self.csv)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.csv.iloc[idx]\n",
    "        sig1, sig2 = load8hz(root+row['first_file']), load8hz(root+row['second_file']) # original files\n",
    "        spkr1, spkr2 = row['first_speaker'], row['second_speaker']\n",
    "        target_vec = np.zeros(len(self.speakers))\n",
    "        target_vec[self.spkr2idx[spkr1]] = 1\n",
    "        target_vec[self.spkr2idx[spkr2]] = 1\n",
    "        return sig1+sig2, target_vec\n",
    "e2eset_train = E2ESet(root, 'overlay-train.csv')\n",
    "e2eset_val = E2ESet(root, 'overlay-val.csv')\n",
    "e2eset_test = E2ESet(root, 'overlay-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load tasnet model\n",
      "load sincnet model\n",
      "using loaded tasnet+sincnet\n"
     ]
    }
   ],
   "source": [
    "tasnet = ConvTasNet.load_model('final.pth.tar').cuda(device)\n",
    "if os.path.exists('models/tasnet.pth'):\n",
    "    print('load tasnet model')\n",
    "    checkpoint = torch.load('models/tasnet.pth')\n",
    "    tasnet.load_state_dict(checkpoint['model_state_dict'])\n",
    "tasnet.train()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "fs=new_sr\n",
    "cw_len=200\n",
    "#cw_shift=10\n",
    "wlen=int(fs*cw_len/1000.00)\n",
    "\n",
    "class MixedClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        cnn_arch = {\n",
    "                'input_dim':wlen,\n",
    "                'fs':fs,\n",
    "                'cnn_N_filt':[80,60,60],\n",
    "                'cnn_len_filt':[251,5,5],\n",
    "                'cnn_max_pool_len':[3,3,3],\n",
    "                'cnn_use_laynorm_inp':True,\n",
    "                'cnn_use_batchnorm_inp':False,\n",
    "                'cnn_use_laynorm':[True,True,True],\n",
    "                'cnn_use_batchnorm':[False,False,False],\n",
    "                'cnn_act':['leaky_relu','leaky_relu','leaky_relu'],\n",
    "                'cnn_drop':[0.0,0.0,0.0]\n",
    "                }\n",
    "        self.cnn_net = SincNet(cnn_arch)\n",
    "\n",
    "        dnn1_arch = {'input_dim': self.cnn_net.out_dim,\n",
    "                  'fc_lay': [2048,2048,2048],\n",
    "                  'fc_drop': [0.0,0.0,0.0], \n",
    "                  'fc_use_batchnorm': [True,True,True],\n",
    "                  'fc_use_laynorm': [False,False,False],\n",
    "                  'fc_use_laynorm_inp': False,\n",
    "                  'fc_use_batchnorm_inp': False,\n",
    "                  'fc_act': ['leaky_relu','leaky_relu','leaky_relu']\n",
    "                  }\n",
    "        self.dnn1 = MLP(dnn1_arch)\n",
    "\n",
    "\n",
    "        dnn2_arch = {'input_dim':2048 ,\n",
    "                  'fc_lay': [20],\n",
    "                  'fc_drop': [0.0], \n",
    "                  'fc_use_batchnorm': [False],\n",
    "                  'fc_use_laynorm': [False],\n",
    "                  'fc_use_laynorm_inp': False,\n",
    "                  'fc_use_batchnorm_inp': False,\n",
    "                  'fc_act': ['linear'] # leakyrelu(1) is just identity mapping\n",
    "                  }\n",
    "        self.dnn2 = MLP(dnn2_arch)\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim = 1)\n",
    "    def forward(self, X):\n",
    "        out = self.cnn_net(X)\n",
    "        out = self.dnn1(out)\n",
    "        out = self.dnn2(out)\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "\n",
    "cls = MixedClassifier().cuda(device)\n",
    "if os.path.exists('models/sincnet.pth'):\n",
    "    print('load sincnet model')\n",
    "    checkpoint = torch.load('models/sincnet.pth')\n",
    "    cls.load_state_dict(checkpoint['model_state_dict'])\n",
    "cls.train()\n",
    "\n",
    "\n",
    "class E2Enet(nn.Module):\n",
    "    def __init__(self, tasnet, cls):\n",
    "        super().__init__()\n",
    "        self.tasnet = tasnet\n",
    "        self.cls = cls\n",
    "    def chop_chunk(self, signal):\n",
    "        batch_size, signal_len = signal.shape\n",
    "        N_fr=signal_len//wlen\n",
    "        chunks = []\n",
    "        for i in range(N_fr):\n",
    "            chunks.append(signal[..., i*wlen:(i+1)*wlen]) # list of N_fr elements, each (batch_size*wlen)\n",
    "        return chunks\n",
    "    def estimate(self, chunks):\n",
    "        out_vecs = []\n",
    "        for chunk in chunks:\n",
    "            out_vecs.append(self.cls(chunk)) # list of N_fr elements, each (batch_size*N_spkr), softmaxed\n",
    "        out_tensor = torch.stack(out_vecs, dim = 1) # batch_size*N_fr*N_spkr\n",
    "        out_tensor = out_tensor.mean(dim = 1) # batch_size*N_spkr\n",
    "        return out_tensor\n",
    "    def forward(self, sig_mixed):\n",
    "        sig12 = self.tasnet(sig_mixed) # batch_size*wlen, batch_size*wlen\n",
    "        sig1, sig2 = sig12[:, 0], sig12[:, 1]\n",
    "        chunks1, chunks2 = self.chop_chunk(sig1), self.chop_chunk(sig2)\n",
    "        pred1, pred2 = self.estimate(chunks1), self.estimate(chunks2)\n",
    "        pred_combined = torch.stack([pred1, pred2], dim = 0) # 2*batch_size*N_spkr\n",
    "        pred_combined , _ = torch.max(pred_combined, dim = 0) # batch_size*N_spkr\n",
    "        return pred_combined\n",
    "\n",
    "e2enet = E2Enet(tasnet, cls).cuda(device)\n",
    "e2enet.train()\n",
    "optimizer = torch.optim.Adam(e2enet.parameters(), lr = 0.001)\n",
    "if os.path.exists('models/e2enet.pth'):\n",
    "    print('load model')\n",
    "    checkpoint = torch.load('models/e2enet.pth')\n",
    "    e2enet.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    loss = checkpoint['loss']\n",
    "    if 'bestacc' in checkpoint:\n",
    "        bestacc = checkpoint['bestacc']\n",
    "    else:\n",
    "        bestacc = 0.0\n",
    "else:\n",
    "    print('using loaded tasnet+sincnet')\n",
    "    bestacc = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max2(tensor):\n",
    "    array = tensor.cpu().detach().numpy()\n",
    "    max2 = []\n",
    "    for row in array:\n",
    "        max2.append(np.argsort(row)[::-1][:2])\n",
    "    return np.array(max2)\n",
    "\n",
    "def compute_corrects(tensor1, tensor2):\n",
    "    max_1, max_2 = find_max2(tensor1), find_max2(tensor2)\n",
    "    batch_size = max_1.shape[0]\n",
    "    batch_corrects = 0\n",
    "    for i in range(batch_size):\n",
    "        if Counter(max_1[i])==Counter(max_2[i]):\n",
    "            batch_corrects+=1\n",
    "    return batch_corrects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff98b9401015419fb7e1349bea2abb19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2755.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Conv-TasNet/src/utils.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  frame = signal.new_tensor(frame).long()  # signal may in GPU or CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test acc: 0.8266787658802178\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3f7c1600a4fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0me2enet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;34m'optimizer_state_dict'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;34m'bestacc'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbestacc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         }, 'models/best-e2enet.pth')\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "e2eloader_test  = torch.utils.data.DataLoader(e2eset_test, batch_size=batch_size, shuffle=True, pin_memory = True, num_workers = 16)\n",
    "with torch.no_grad():    \n",
    "    corrects = 0\n",
    "    for batch_idx, (mixed_sig, target) in enumerate(tqdm(e2eloader_test)):\n",
    "        mixed_sig, target = mixed_sig.float().cuda(device), target.float().cuda(device)\n",
    "        out = e2enet(mixed_sig)\n",
    "        corrects += compute_corrects(out, target)\n",
    "    print('test acc:', corrects/len(e2eset_test))\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
