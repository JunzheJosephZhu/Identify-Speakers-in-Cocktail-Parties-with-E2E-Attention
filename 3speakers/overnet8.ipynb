{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import glob\n",
    "from lxml.html import parse\n",
    "from sphfile import SPHFile\n",
    "import pydub\n",
    "import audiosegment\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.func(x)\n",
    "sr = 16000\n",
    "dropout = 0.3\n",
    "half = False\n",
    "root = '../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 2\n",
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OverlayDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv, compute_original = False):\n",
    "        super().__init__()\n",
    "        self.overlays = pd.read_csv(csv)\n",
    "        self.speakers = list(set(self.overlays['first_speaker']))\n",
    "        self.speakers.sort()\n",
    "        self.spkr2idx = {spkr:i for i, spkr in enumerate(self.speakers)}\n",
    "        self.compute_original = compute_original\n",
    "    def __len__(self):\n",
    "        return len(self.overlays)\n",
    "    def __getitem__(self, idx):\n",
    "        overlay = self.overlays.iloc[idx]\n",
    "        first_segment = np.load(root+overlay['first_file'])/(2**15)\n",
    "        second_segment = np.load(root+overlay['second_file'])/(2**15)\n",
    "        third_segment = np.load(root+overlay['third_file'])/(2**15)\n",
    "        max_len = max(len(first_segment), len(second_segment), len(third_segment))\n",
    "        #padding to compensate rounding errors\n",
    "        if max_len>len(first_segment):\n",
    "            padding = np.zeros(max_len-len(first_segment))\n",
    "            first_segment = np.concatenate((first_segment, padding))\n",
    "        \n",
    "        if max_len>len(second_segment):\n",
    "            padding = np.zeros(max_len-len(second_segment))\n",
    "            second_segment = np.concatenate((second_segment, padding))\n",
    "            \n",
    "        if max_len>len(third_segment):\n",
    "            padding = np.zeros(max_len-len(third_segment))\n",
    "            third_segment = np.concatenate((third_segment, padding))\n",
    "        \n",
    "        first_idx  = self.spkr2idx[overlay['first_speaker']]\n",
    "        second_idx = self.spkr2idx[overlay['second_speaker']]\n",
    "        third_idx = self.spkr2idx[overlay['third_speaker']]\n",
    "\n",
    "        target = np.zeros(len(self.speakers))\n",
    "        target[first_idx] = 1.0\n",
    "        target[second_idx] = 1.0\n",
    "        target[third_idx] = 1.0\n",
    "        \n",
    "        if self.compute_original:\n",
    "            return self.make_spectrogram(first_segment), self.make_spectrogram(second_segment),\\\n",
    "                self.make_spectrogram(third_segment), self.make_spectrogram(first_segment+second_segment), target\n",
    "        else:\n",
    "            return self.make_spectrogram(first_segment+second_segment+third_segment), target\n",
    "    def make_spectrogram(self, segment):\n",
    "        segment = segment[50:-50] # make size 200\n",
    "        S = librosa.feature.melspectrogram(segment, n_mels = 256, n_fft = 1024, hop_length = 160) # 32 ms window, 10 ms hop\n",
    "        S_dB = librosa.power_to_db(S).T[None, :, :] # add channel dimension\n",
    "        return S_dB\n",
    "\n",
    "trainset = OverlayDataSet('overlay-train.csv', False)\n",
    "valset = OverlayDataSet('overlay-val.csv', False)\n",
    "testset = OverlayDataSet('overlay-test.csv', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.884724 -50.115276 (1, 200, 256) [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spec3, target = trainset[0]\n",
    "plt.figure(figsize = (20, 6))\n",
    "if trainset.compute_original:\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(spec1[0].T)\n",
    "    plt.subplot(132)\n",
    "    plt.imshow(spec2[0].T)\n",
    "    plt.subplot(133)\n",
    "    plt.imshow(spec3[0].T)\n",
    "print(spec3.max(), spec3.min(), spec3.shape, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maybe try drastically increasing channel number in residual attention stage to see if it overfits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('bestacc:', 0.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import functools\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.input_channels = input_channels\n",
    "        self.output_channels = output_channels\n",
    "        self.stride = stride\n",
    "        self.bn1 = nn.BatchNorm2d(input_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(input_channels, output_channels, 1, 1, bias = False)\n",
    "        self.bn2 = nn.BatchNorm2d(output_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(output_channels, output_channels, 3, stride, padding = 1, bias = False)\n",
    "        self.bn3 = nn.BatchNorm2d(output_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv3 = nn.Conv2d(output_channels, output_channels, 1, 1, bias = False)\n",
    "        self.conv4 = nn.Conv2d(input_channels, output_channels , 1, stride, bias = False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.bn1(x)\n",
    "        out1 = self.relu(out)\n",
    "        out = self.conv1(out1)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv3(out)\n",
    "        if (self.input_channels != self.output_channels) or (self.stride !=1 ):\n",
    "            residual = self.conv4(out1)\n",
    "        out += residual\n",
    "        return out\n",
    "\n",
    "class AttentionModule_stage1(nn.Module):\n",
    "    # input size is 56*56\n",
    "    def __init__(self, in_channels, out_channels, size1=(200, 128), size2=(100, 64), size3=(50, 32)):\n",
    "        super(AttentionModule_stage1, self).__init__()\n",
    "        self.first_residual_blocks = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.trunk_branches = nn.Sequential(\n",
    "            ResidualBlock(in_channels, out_channels),\n",
    "            ResidualBlock(in_channels, out_channels)\n",
    "         )\n",
    "\n",
    "        self.mpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.softmax1_blocks = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.skip1_connection_residual_block = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.mpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.softmax2_blocks = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.skip2_connection_residual_block = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.mpool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.softmax3_blocks = nn.Sequential(\n",
    "            ResidualBlock(in_channels, out_channels),\n",
    "            ResidualBlock(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "        self.interpolation3 = nn.UpsamplingBilinear2d(size=size3)\n",
    "\n",
    "        self.softmax4_blocks = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.interpolation2 = nn.UpsamplingBilinear2d(size=size2)\n",
    "\n",
    "        self.softmax5_blocks = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.interpolation1 = nn.UpsamplingBilinear2d(size=size1)\n",
    "\n",
    "        self.softmax6_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels , kernel_size = 1, stride = 1, bias = False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels , kernel_size = 1, stride = 1, bias = False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.last_blocks = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #batch_size, nheads, length, n_mels = x.shape\n",
    "        x = self.first_residual_blocks(x)\n",
    "        out_trunk = self.trunk_branches(x)\n",
    "        out_mpool1 = self.mpool1(x) # 100x64\n",
    "        out_softmax1 = self.softmax1_blocks(out_mpool1)\n",
    "        out_skip1_connection = self.skip1_connection_residual_block(out_softmax1)\n",
    "        out_mpool2 = self.mpool2(out_softmax1) # 50x32\n",
    "        out_softmax2 = self.softmax2_blocks(out_mpool2)\n",
    "        out_skip2_connection = self.skip2_connection_residual_block(out_softmax2)\n",
    "        out_mpool3 = self.mpool3(out_softmax2) # 25x16\n",
    "        out_softmax3 = self.softmax3_blocks(out_mpool3) \n",
    "        out_interp3 = self.interpolation3(out_softmax3) + out_softmax2\n",
    "        out = out_interp3 + out_skip2_connection\n",
    "        out_softmax4 = self.softmax4_blocks(out)\n",
    "        out_interp2 = self.interpolation2(out_softmax4) + out_softmax1\n",
    "        out = out_interp2 + out_skip1_connection\n",
    "        out_softmax5 = self.softmax5_blocks(out)\n",
    "        out_interp1 = self.interpolation1(out_softmax5) + out_trunk\n",
    "        out_softmax6 = self.softmax6_blocks(out_interp1)\n",
    "        out = (1 + out_softmax6) * out_trunk\n",
    "        out_last = self.last_blocks(out)\n",
    "        return out_last\n",
    "\n",
    "num_heads = 12 # Residual Attention Channels\n",
    "num_heads_2 = 4 # MHA heads\n",
    "\n",
    "\n",
    "class OverlayNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ln = nn.LayerNorm(256)\n",
    "        self.downsample1 = ResidualBlock(1, num_heads, (1, 2))\n",
    "        self.res_att = AttentionModule_stage1(num_heads, num_heads)  # batch_size * num_heads * L *128\n",
    "        self.downsample2 = nn.Sequential(ResidualBlock(num_heads, num_heads//2),\n",
    "                                        ResidualBlock(num_heads//2, num_heads//4),\n",
    "                                        ResidualBlock(num_heads//4, num_heads//4, (1, 2)))\n",
    "        self.reshape =  Lambda(lambda x: x.permute((1, 2, 0, 3))) # L * batch_size * (num_heads*128)\n",
    "        self.lstm = nn.LSTM(64, 32, 2, batch_first = False, bidirectional = True, dropout = dropout) # L * batch_size * 200 * n_hidden\n",
    "        self.mha =  torch.nn.MultiheadAttention(64, num_heads = num_heads_2, dropout=dropout, bias=True, kdim=64, vdim=64) # L * N * 64\n",
    "        self.fc1 = nn.Linear(64, 32)\n",
    "        self.average = Lambda(lambda x: x.mean(dim = 0)) # batch * n_hidden\n",
    "        self.tanh = nn.Tanh()\n",
    "        #self.norm = Lambda(lambda x: torch.nn.functional.normalize(x, p = 2, dim = 1)) # L2 normalize across n_hidden\n",
    "        self.fc2 = nn.Linear(32, 20)\n",
    "        self.softmax = nn.Softmax(1)\n",
    "    def forward(self, X):\n",
    "        X = self.ln(X)\n",
    "        X = self.downsample1(X)\n",
    "        #print('first downsample ', X.shape)\n",
    "        X = self.res_att(X)\n",
    "        #print('residual attention ', X.shape)\n",
    "        X = self.downsample2(X)\n",
    "        #print('second downsample ', X.shape)\n",
    "        X = self.reshape(X)\n",
    "        X1, X2, X3 = X[0], X[1], X[2]\n",
    "        X1,_ = self.lstm(X1)\n",
    "        X2,_ = self.lstm(X1)\n",
    "        X3,_ = self.lstm(X3)\n",
    "        #print('lstm ', X.shape)\n",
    "        X1,_ = self.mha(X1, X1, X1)\n",
    "        X2,_ = self.mha(X2, X2, X2)\n",
    "        X3,_ = self.mha(X3, X3, X3)\n",
    "        #print('mha ', X.shape)\n",
    "        X1 = self.fc1(X1)\n",
    "        X2 = self.fc1(X2)\n",
    "        X3 = self.fc1(X3)\n",
    "        #print('dense ', X.shape)\n",
    "        X1 = self.average(X1)\n",
    "        X2 = self.average(X2)\n",
    "        X3 = self.average(X3)\n",
    "        #print('mean ', X.shape)\n",
    "        X1 = self.tanh(X1)\n",
    "        X2 = self.tanh(X2)\n",
    "        X3 = self.tanh(X3)\n",
    "        X1 = self.fc2(X1)\n",
    "        X2 = self.fc2(X2)\n",
    "        X3 = self.fc2(X3)\n",
    "        X1 = self.softmax(X1)\n",
    "        X2 = self.softmax(X2)\n",
    "        X3 = self.softmax(X3)\n",
    "        X = torch.stack([X1,X2,X3], dim=0)\n",
    "        X,_ = torch.max(X, dim=0)\n",
    "        return X\n",
    "    \n",
    "    \n",
    "overnet = OverlayNet().cuda(device)\n",
    "    \n",
    "# tune hidden layers smaller if overfit\n",
    "optimizer = torch.optim.Adam(overnet.parameters(), 0.001)\n",
    "\n",
    "if os.path.exists('models/overnet8.pth'):\n",
    "    print('load model')\n",
    "    checkpoint = torch.load('models/overnet8.pth')\n",
    "    overnet.load_state_dict(checkpoint['model_state_dict'])\n",
    "    try:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    except:\n",
    "        print('cannot load optimizer')\n",
    "    loss = checkpoint['loss']\n",
    "    if 'bestacc' in checkpoint:\n",
    "        bestacc = checkpoint['bestacc']\n",
    "    else:\n",
    "        bestacc = 0.0\n",
    "else:\n",
    "    print('initializing new model')\n",
    "    bestacc = 0.0\n",
    "    \n",
    "if half:\n",
    "    overnet.half()  # convert to half precision\n",
    "    for layer in overnet.modules():\n",
    "        if isinstance(layer, nn.BatchNorm2d):\n",
    "            layer.float()\n",
    "            \n",
    "overnet.train()\n",
    "'bestacc:', bestacc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Also Do metrics on hitting a single person right\n",
    "## Theoretical justification that when reducing number of channels, neural network could learn to pair similar spectrum representations with each other: only pitch lines that are greater than a certain threshold will pass relu and become postivie. Batchnorm makes this effect stronger. Therefore, when two channels represent spectrums of different people, when they are added the output will be nothing if it doesn't pass the relu threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "def find_max3(tensor):\n",
    "    array = tensor.cpu().detach().numpy()\n",
    "    max3 = []\n",
    "    for row in array:\n",
    "        max3.append(np.argsort(row)[::-1][:3])\n",
    "    return np.array(max3)\n",
    "\n",
    "def compute_corrects(tensor1, tensor2):\n",
    "    max_1, max_2 = find_max3(tensor1), find_max3(tensor2)\n",
    "    batch_size = max_1.shape[0]\n",
    "    batch_corrects = 0\n",
    "    for i in range(batch_size):\n",
    "        if Counter(max_1[i])==Counter(max_2[i]):\n",
    "            batch_corrects+=1\n",
    "    return batch_corrects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e3c5743856f4afeb965a80f7348a529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=24795.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 0.066 accuracy: 0.775\n",
      "[1,   400] loss: 0.063 accuracy: 0.786\n",
      "[1,   600] loss: 0.064 accuracy: 0.783\n",
      "[1,   800] loss: 0.063 accuracy: 0.782\n",
      "[1,  1000] loss: 0.064 accuracy: 0.785\n",
      "[1,  1200] loss: 0.063 accuracy: 0.780\n",
      "[1,  1400] loss: 0.064 accuracy: 0.779\n",
      "[1,  1600] loss: 0.065 accuracy: 0.779\n",
      "[1,  1800] loss: 0.063 accuracy: 0.786\n",
      "[1,  2000] loss: 0.064 accuracy: 0.783\n",
      "[1,  2200] loss: 0.064 accuracy: 0.779\n",
      "[1,  2400] loss: 0.066 accuracy: 0.778\n",
      "[1,  2600] loss: 0.065 accuracy: 0.778\n",
      "[1,  2800] loss: 0.064 accuracy: 0.780\n",
      "[1,  3000] loss: 0.064 accuracy: 0.780\n",
      "[1,  3200] loss: 0.064 accuracy: 0.782\n",
      "[1,  3400] loss: 0.065 accuracy: 0.777\n",
      "[1,  3600] loss: 0.065 accuracy: 0.774\n",
      "[1,  3800] loss: 0.066 accuracy: 0.773\n",
      "[1,  4000] loss: 0.065 accuracy: 0.779\n",
      "[1,  4200] loss: 0.064 accuracy: 0.779\n",
      "[1,  4400] loss: 0.064 accuracy: 0.779\n",
      "[1,  4600] loss: 0.064 accuracy: 0.780\n",
      "[1,  4800] loss: 0.066 accuracy: 0.772\n",
      "[1,  5000] loss: 0.064 accuracy: 0.783\n",
      "[1,  5200] loss: 0.065 accuracy: 0.778\n",
      "[1,  5400] loss: 0.065 accuracy: 0.779\n",
      "[1,  5600] loss: 0.064 accuracy: 0.781\n",
      "[1,  5800] loss: 0.064 accuracy: 0.783\n",
      "[1,  6000] loss: 0.064 accuracy: 0.777\n",
      "[1,  6200] loss: 0.064 accuracy: 0.784\n",
      "[1,  6400] loss: 0.065 accuracy: 0.778\n",
      "[1,  6600] loss: 0.067 accuracy: 0.770\n",
      "[1,  6800] loss: 0.064 accuracy: 0.780\n",
      "[1,  7000] loss: 0.066 accuracy: 0.778\n",
      "[1,  7200] loss: 0.065 accuracy: 0.773\n",
      "[1,  7400] loss: 0.066 accuracy: 0.773\n",
      "[1,  7600] loss: 0.067 accuracy: 0.769\n",
      "[1,  7800] loss: 0.065 accuracy: 0.775\n",
      "[1,  8000] loss: 0.064 accuracy: 0.786\n",
      "[1,  8200] loss: 0.064 accuracy: 0.783\n",
      "[1,  8400] loss: 0.065 accuracy: 0.779\n",
      "[1,  8600] loss: 0.065 accuracy: 0.783\n",
      "[1,  8800] loss: 0.065 accuracy: 0.779\n",
      "[1,  9000] loss: 0.064 accuracy: 0.784\n",
      "[1,  9200] loss: 0.064 accuracy: 0.782\n",
      "[1,  9400] loss: 0.065 accuracy: 0.778\n",
      "[1,  9600] loss: 0.065 accuracy: 0.779\n",
      "[1,  9800] loss: 0.064 accuracy: 0.781\n",
      "[1, 10000] loss: 0.064 accuracy: 0.787\n",
      "[1, 10200] loss: 0.065 accuracy: 0.778\n",
      "[1, 10400] loss: 0.065 accuracy: 0.780\n",
      "[1, 10600] loss: 0.065 accuracy: 0.781\n",
      "[1, 10800] loss: 0.064 accuracy: 0.780\n",
      "[1, 11000] loss: 0.066 accuracy: 0.779\n",
      "[1, 11200] loss: 0.064 accuracy: 0.780\n",
      "[1, 11400] loss: 0.063 accuracy: 0.790\n",
      "[1, 11600] loss: 0.064 accuracy: 0.784\n",
      "[1, 11800] loss: 0.064 accuracy: 0.783\n",
      "[1, 12000] loss: 0.066 accuracy: 0.775\n",
      "[1, 12200] loss: 0.064 accuracy: 0.786\n",
      "[1, 12400] loss: 0.065 accuracy: 0.775\n",
      "[1, 12600] loss: 0.064 accuracy: 0.785\n",
      "[1, 12800] loss: 0.065 accuracy: 0.778\n",
      "[1, 13000] loss: 0.063 accuracy: 0.782\n",
      "[1, 13200] loss: 0.063 accuracy: 0.788\n",
      "[1, 13400] loss: 0.064 accuracy: 0.783\n",
      "[1, 13600] loss: 0.065 accuracy: 0.780\n",
      "[1, 13800] loss: 0.065 accuracy: 0.775\n",
      "[1, 14000] loss: 0.064 accuracy: 0.782\n",
      "[1, 14200] loss: 0.066 accuracy: 0.772\n",
      "[1, 14400] loss: 0.064 accuracy: 0.778\n",
      "[1, 14600] loss: 0.065 accuracy: 0.775\n",
      "[1, 14800] loss: 0.065 accuracy: 0.784\n",
      "[1, 15000] loss: 0.065 accuracy: 0.779\n",
      "[1, 15200] loss: 0.064 accuracy: 0.779\n",
      "[1, 15400] loss: 0.063 accuracy: 0.785\n",
      "[1, 15600] loss: 0.065 accuracy: 0.778\n",
      "[1, 15800] loss: 0.063 accuracy: 0.783\n",
      "[1, 16000] loss: 0.066 accuracy: 0.778\n",
      "[1, 16200] loss: 0.064 accuracy: 0.784\n",
      "[1, 16400] loss: 0.064 accuracy: 0.783\n",
      "[1, 16600] loss: 0.063 accuracy: 0.787\n",
      "[1, 16800] loss: 0.065 accuracy: 0.776\n",
      "[1, 17000] loss: 0.065 accuracy: 0.781\n",
      "[1, 17200] loss: 0.066 accuracy: 0.774\n",
      "[1, 17400] loss: 0.063 accuracy: 0.791\n",
      "[1, 17600] loss: 0.065 accuracy: 0.780\n",
      "[1, 17800] loss: 0.066 accuracy: 0.775\n",
      "[1, 18000] loss: 0.065 accuracy: 0.775\n",
      "[1, 18200] loss: 0.064 accuracy: 0.784\n",
      "[1, 18400] loss: 0.063 accuracy: 0.781\n",
      "[1, 18600] loss: 0.063 accuracy: 0.790\n",
      "[1, 18800] loss: 0.065 accuracy: 0.778\n",
      "[1, 19000] loss: 0.063 accuracy: 0.788\n",
      "[1, 19200] loss: 0.065 accuracy: 0.780\n",
      "[1, 19400] loss: 0.064 accuracy: 0.779\n",
      "[1, 19600] loss: 0.064 accuracy: 0.782\n",
      "[1, 19800] loss: 0.064 accuracy: 0.781\n",
      "[1, 20000] loss: 0.064 accuracy: 0.783\n",
      "[1, 20200] loss: 0.065 accuracy: 0.777\n",
      "[1, 20400] loss: 0.062 accuracy: 0.792\n",
      "[1, 20600] loss: 0.065 accuracy: 0.782\n",
      "[1, 20800] loss: 0.063 accuracy: 0.785\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-fa5d85a6fff2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0movernet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-4b79331f7df5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mX3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;31m#print('lstm ', X.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0mX2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mX3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask)\u001b[0m\n\u001b[1;32m    817\u001b[0m                 \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m                 \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneed_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneed_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m                 attn_mask=attn_mask)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v)\u001b[0m\n\u001b[1;32m   3218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3219\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muse_separate_proj_weight\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3220\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3221\u001b[0m             \u001b[0;31m# self-attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3222\u001b[0m             \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_proj_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_proj_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, pin_memory = True, num_workers = 16)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True, pin_memory = True, num_workers = 16)\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "for epoch in range(64):\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "    for batch_idx, (spec, target) in enumerate(tqdm(trainloader)):\n",
    "        optimizer.zero_grad()\n",
    "        spec, target = spec.float(), target.float()\n",
    "        if half:\n",
    "            spec, target = spec.half(),target.half()\n",
    "        spec = spec.cuda(device)\n",
    "        target = target.cuda(device)\n",
    "\n",
    "        out = overnet(spec)\n",
    "        loss = criterion(out, target)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(overnet.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "                \n",
    "        running_loss += loss.item()\n",
    "        running_accuracy += compute_corrects(out, target)/batch_size\n",
    "        if batch_idx % 200 == 199:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f accuracy: %.3f' % \n",
    "                  (epoch + 1, batch_idx + 1, running_loss / 200, running_accuracy / 200))\n",
    "            running_loss = 0.0\n",
    "            running_accuracy = 0.0\n",
    "            torch.save({\n",
    "            'model_state_dict': overnet.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss\n",
    "            }, 'models/overnet8.pth')\n",
    "\n",
    "        \n",
    "    with torch.no_grad():    \n",
    "        corrects = 0\n",
    "        for batch_idx, (spec, target) in enumerate(tqdm(valloader)):\n",
    "            spec, target = spec.float(), target.float()\n",
    "            if half:\n",
    "                spec, target = spec.half(), target.half()\n",
    "            spec = spec.cuda(device)\n",
    "            target = target.cuda(device)\n",
    "            overnet.eval()\n",
    "            out = overnet(spec) \n",
    "            corrects += compute_corrects(out, target)\n",
    "        print('val acc:', corrects/len(valset))\n",
    "        if corrects/len(valset) > bestacc:\n",
    "            bestacc = corrects/len(valset)\n",
    "            torch.save({\n",
    "            'model_state_dict': overnet.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            'bestacc': bestacc\n",
    "            }, 'models/best-overnet8.pth')\n",
    "        overnet.train()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bd6c8194e374adda1218c652cb30d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3100.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test acc: 0.7829048195200645\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('models/best-overnet8.pth')\n",
    "overnet.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True, pin_memory = True, num_workers = 16)\n",
    "\n",
    "overnet.eval()\n",
    "corrects = 0\n",
    "for batch_idx, (spec, target) in enumerate(tqdm(testloader)):\n",
    "    spec, target = spec.float(), target.float()\n",
    "    if half:\n",
    "        spec, target = spec.half(), target.half()\n",
    "    spec = spec.cuda(device)\n",
    "    target = target.cuda(device)\n",
    "    out = overnet(spec) \n",
    "    corrects += compute_corrects(out, target)\n",
    "print('test acc:', corrects/len(testset))\n",
    "overnet.train()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
