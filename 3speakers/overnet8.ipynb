{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import glob\n",
    "from lxml.html import parse\n",
    "from sphfile import SPHFile\n",
    "import pydub\n",
    "import audiosegment\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.func(x)\n",
    "sr = 16000\n",
    "dropout = 0.3\n",
    "half = False\n",
    "root = '../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 2\n",
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OverlayDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv, compute_original = False):\n",
    "        super().__init__()\n",
    "        self.overlays = pd.read_csv(csv)\n",
    "        self.speakers = list(set(self.overlays['first_speaker']))\n",
    "        self.speakers.sort()\n",
    "        self.spkr2idx = {spkr:i for i, spkr in enumerate(self.speakers)}\n",
    "        self.compute_original = compute_original\n",
    "    def __len__(self):\n",
    "        return len(self.overlays)\n",
    "    def __getitem__(self, idx):\n",
    "        overlay = self.overlays.iloc[idx]\n",
    "        first_segment = np.load(root+overlay['first_file'])/(2**15)\n",
    "        second_segment = np.load(root+overlay['second_file'])/(2**15)\n",
    "        third_segment = np.load(root+overlay['third_file'])/(2**15)\n",
    "        max_len = max(len(first_segment), len(second_segment), len(third_segment))\n",
    "        #padding to compensate rounding errors\n",
    "        if max_len>len(first_segment):\n",
    "            padding = np.zeros(max_len-len(first_segment))\n",
    "            first_segment = np.concatenate((first_segment, padding))\n",
    "        \n",
    "        if max_len>len(second_segment):\n",
    "            padding = np.zeros(max_len-len(second_segment))\n",
    "            second_segment = np.concatenate((second_segment, padding))\n",
    "            \n",
    "        if max_len>len(third_segment):\n",
    "            padding = np.zeros(max_len-len(third_segment))\n",
    "            third_segment = np.concatenate((third_segment, padding))\n",
    "        \n",
    "        first_idx  = self.spkr2idx[overlay['first_speaker']]\n",
    "        second_idx = self.spkr2idx[overlay['second_speaker']]\n",
    "        third_idx = self.spkr2idx[overlay['third_speaker']]\n",
    "\n",
    "        target = np.zeros(len(self.speakers))\n",
    "        target[first_idx] = 1.0\n",
    "        target[second_idx] = 1.0\n",
    "        target[third_idx] = 1.0\n",
    "        \n",
    "        if self.compute_original:\n",
    "            return self.make_spectrogram(first_segment), self.make_spectrogram(second_segment),\\\n",
    "                self.make_spectrogram(third_segment), self.make_spectrogram(first_segment+second_segment), target\n",
    "        else:\n",
    "            return self.make_spectrogram(first_segment+second_segment+third_segment), target\n",
    "    def make_spectrogram(self, segment):\n",
    "        segment = segment[50:-50] # make size 200\n",
    "        S = librosa.feature.melspectrogram(segment, n_mels = 256, n_fft = 1024, hop_length = 160) # 32 ms window, 10 ms hop\n",
    "        S_dB = librosa.power_to_db(S).T[None, :, :] # add channel dimension\n",
    "        return S_dB\n",
    "\n",
    "trainset = OverlayDataSet('overlay-train.csv', False)\n",
    "valset = OverlayDataSet('overlay-val.csv', False)\n",
    "testset = OverlayDataSet('overlay-test.csv', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.884724 -50.115276 (1, 200, 256) [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spec3, target = trainset[0]\n",
    "plt.figure(figsize = (20, 6))\n",
    "if trainset.compute_original:\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(spec1[0].T)\n",
    "    plt.subplot(132)\n",
    "    plt.imshow(spec2[0].T)\n",
    "    plt.subplot(133)\n",
    "    plt.imshow(spec3[0].T)\n",
    "print(spec3.max(), spec3.min(), spec3.shape, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maybe try drastically increasing channel number in residual attention stage to see if it overfits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('bestacc:', 0.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import functools\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.input_channels = input_channels\n",
    "        self.output_channels = output_channels\n",
    "        self.stride = stride\n",
    "        self.bn1 = nn.BatchNorm2d(input_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(input_channels, output_channels, 1, 1, bias = False)\n",
    "        self.bn2 = nn.BatchNorm2d(output_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(output_channels, output_channels, 3, stride, padding = 1, bias = False)\n",
    "        self.bn3 = nn.BatchNorm2d(output_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv3 = nn.Conv2d(output_channels, output_channels, 1, 1, bias = False)\n",
    "        self.conv4 = nn.Conv2d(input_channels, output_channels , 1, stride, bias = False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.bn1(x)\n",
    "        out1 = self.relu(out)\n",
    "        out = self.conv1(out1)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv3(out)\n",
    "        if (self.input_channels != self.output_channels) or (self.stride !=1 ):\n",
    "            residual = self.conv4(out1)\n",
    "        out += residual\n",
    "        return out\n",
    "\n",
    "class AttentionModule_stage1(nn.Module):\n",
    "    # input size is 56*56\n",
    "    def __init__(self, in_channels, out_channels, size1=(200, 128), size2=(100, 64), size3=(50, 32)):\n",
    "        super(AttentionModule_stage1, self).__init__()\n",
    "        self.first_residual_blocks = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.trunk_branches = nn.Sequential(\n",
    "            ResidualBlock(in_channels, out_channels),\n",
    "            ResidualBlock(in_channels, out_channels)\n",
    "         )\n",
    "\n",
    "        self.mpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.softmax1_blocks = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.skip1_connection_residual_block = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.mpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.softmax2_blocks = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.skip2_connection_residual_block = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.mpool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.softmax3_blocks = nn.Sequential(\n",
    "            ResidualBlock(in_channels, out_channels),\n",
    "            ResidualBlock(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "        self.interpolation3 = nn.UpsamplingBilinear2d(size=size3)\n",
    "\n",
    "        self.softmax4_blocks = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.interpolation2 = nn.UpsamplingBilinear2d(size=size2)\n",
    "\n",
    "        self.softmax5_blocks = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "        self.interpolation1 = nn.UpsamplingBilinear2d(size=size1)\n",
    "\n",
    "        self.softmax6_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels , kernel_size = 1, stride = 1, bias = False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels , kernel_size = 1, stride = 1, bias = False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.last_blocks = ResidualBlock(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #batch_size, nheads, length, n_mels = x.shape\n",
    "        x = self.first_residual_blocks(x)\n",
    "        out_trunk = self.trunk_branches(x)\n",
    "        out_mpool1 = self.mpool1(x) # 100x64\n",
    "        out_softmax1 = self.softmax1_blocks(out_mpool1)\n",
    "        out_skip1_connection = self.skip1_connection_residual_block(out_softmax1)\n",
    "        out_mpool2 = self.mpool2(out_softmax1) # 50x32\n",
    "        out_softmax2 = self.softmax2_blocks(out_mpool2)\n",
    "        out_skip2_connection = self.skip2_connection_residual_block(out_softmax2)\n",
    "        out_mpool3 = self.mpool3(out_softmax2) # 25x16\n",
    "        out_softmax3 = self.softmax3_blocks(out_mpool3) \n",
    "        out_interp3 = self.interpolation3(out_softmax3) + out_softmax2\n",
    "        out = out_interp3 + out_skip2_connection\n",
    "        out_softmax4 = self.softmax4_blocks(out)\n",
    "        out_interp2 = self.interpolation2(out_softmax4) + out_softmax1\n",
    "        out = out_interp2 + out_skip1_connection\n",
    "        out_softmax5 = self.softmax5_blocks(out)\n",
    "        out_interp1 = self.interpolation1(out_softmax5) + out_trunk\n",
    "        out_softmax6 = self.softmax6_blocks(out_interp1)\n",
    "        out = (1 + out_softmax6) * out_trunk\n",
    "        out_last = self.last_blocks(out)\n",
    "        return out_last\n",
    "\n",
    "num_heads = 12 # Residual Attention Channels\n",
    "num_heads_2 = 4 # MHA heads\n",
    "\n",
    "\n",
    "class OverlayNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ln = nn.LayerNorm(256)\n",
    "        self.downsample1 = ResidualBlock(1, num_heads, (1, 2))\n",
    "        self.res_att = AttentionModule_stage1(num_heads, num_heads)  # batch_size * num_heads * L *128\n",
    "        self.downsample2 = nn.Sequential(ResidualBlock(num_heads, num_heads//2),\n",
    "                                        ResidualBlock(num_heads//2, num_heads//4),\n",
    "                                        ResidualBlock(num_heads//4, num_heads//4, (1, 2)))\n",
    "        self.reshape =  Lambda(lambda x: x.permute((1, 2, 0, 3))) # L * batch_size * (num_heads*128)\n",
    "        self.lstm = nn.LSTM(64, 32, 2, batch_first = False, bidirectional = True, dropout = dropout) # L * batch_size * 200 * n_hidden\n",
    "        self.mha =  torch.nn.MultiheadAttention(64, num_heads = num_heads_2, dropout=dropout, bias=True, kdim=64, vdim=64) # L * N * 64\n",
    "        self.fc1 = nn.Linear(64, 32)\n",
    "        self.average = Lambda(lambda x: x.mean(dim = 0)) # batch * n_hidden\n",
    "        self.tanh = nn.Tanh()\n",
    "        #self.norm = Lambda(lambda x: torch.nn.functional.normalize(x, p = 2, dim = 1)) # L2 normalize across n_hidden\n",
    "        self.fc2 = nn.Linear(32, 20)\n",
    "        self.softmax = nn.Softmax(1)\n",
    "    def forward(self, X):\n",
    "        X = self.ln(X)\n",
    "        X = self.downsample1(X)\n",
    "        #print('first downsample ', X.shape)\n",
    "        X = self.res_att(X)\n",
    "        #print('residual attention ', X.shape)\n",
    "        X = self.downsample2(X)\n",
    "        #print('second downsample ', X.shape)\n",
    "        X = self.reshape(X)\n",
    "        X1, X2, X3 = X[0], X[1], X[2]\n",
    "        X1,_ = self.lstm(X1)\n",
    "        X2,_ = self.lstm(X1)\n",
    "        X3,_ = self.lstm(X3)\n",
    "        #print('lstm ', X.shape)\n",
    "        X1,_ = self.mha(X1, X1, X1)\n",
    "        X2,_ = self.mha(X2, X2, X2)\n",
    "        X3,_ = self.mha(X3, X3, X3)\n",
    "        #print('mha ', X.shape)\n",
    "        X1 = self.fc1(X1)\n",
    "        X2 = self.fc1(X2)\n",
    "        X3 = self.fc1(X3)\n",
    "        #print('dense ', X.shape)\n",
    "        X1 = self.average(X1)\n",
    "        X2 = self.average(X2)\n",
    "        X3 = self.average(X3)\n",
    "        #print('mean ', X.shape)\n",
    "        X1 = self.tanh(X1)\n",
    "        X2 = self.tanh(X2)\n",
    "        X3 = self.tanh(X3)\n",
    "        X1 = self.fc2(X1)\n",
    "        X2 = self.fc2(X2)\n",
    "        X3 = self.fc2(X3)\n",
    "        X1 = self.softmax(X1)\n",
    "        X2 = self.softmax(X2)\n",
    "        X3 = self.softmax(X3)\n",
    "        X = torch.stack([X1,X2,X3], dim=0)\n",
    "        X,_ = torch.max(X, dim=0)\n",
    "        return X\n",
    "    \n",
    "    \n",
    "overnet = OverlayNet().cuda(device)\n",
    "    \n",
    "# tune hidden layers smaller if overfit\n",
    "optimizer = torch.optim.Adam(overnet.parameters(), 0.001)\n",
    "\n",
    "if os.path.exists('models/overnet8.pth'):\n",
    "    print('load model')\n",
    "    checkpoint = torch.load('models/overnet8.pth')\n",
    "    overnet.load_state_dict(checkpoint['model_state_dict'])\n",
    "    try:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    except:\n",
    "        print('cannot load optimizer')\n",
    "    loss = checkpoint['loss']\n",
    "    if 'bestacc' in checkpoint:\n",
    "        bestacc = checkpoint['bestacc']\n",
    "    else:\n",
    "        bestacc = 0.0\n",
    "else:\n",
    "    print('initializing new model')\n",
    "    bestacc = 0.0\n",
    "    \n",
    "if half:\n",
    "    overnet.half()  # convert to half precision\n",
    "    for layer in overnet.modules():\n",
    "        if isinstance(layer, nn.BatchNorm2d):\n",
    "            layer.float()\n",
    "            \n",
    "overnet.train()\n",
    "'bestacc:', bestacc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Also Do metrics on hitting a single person right\n",
    "## Theoretical justification that when reducing number of channels, neural network could learn to pair similar spectrum representations with each other: only pitch lines that are greater than a certain threshold will pass relu and become postivie. Batchnorm makes this effect stronger. Therefore, when two channels represent spectrums of different people, when they are added the output will be nothing if it doesn't pass the relu threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "def find_max3(tensor):\n",
    "    array = tensor.cpu().detach().numpy()\n",
    "    max3 = []\n",
    "    for row in array:\n",
    "        max3.append(np.argsort(row)[::-1][:3])\n",
    "    return np.array(max3)\n",
    "\n",
    "def compute_corrects(tensor1, tensor2):\n",
    "    max_1, max_2 = find_max3(tensor1), find_max3(tensor2)\n",
    "    batch_size = max_1.shape[0]\n",
    "    batch_corrects = 0\n",
    "    for i in range(batch_size):\n",
    "        if Counter(max_1[i])==Counter(max_2[i]):\n",
    "            batch_corrects+=1\n",
    "    return batch_corrects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bf5371030a746f5800318bbc60c3e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=24795.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 0.073 accuracy: 0.749\n",
      "[1,   400] loss: 0.072 accuracy: 0.751\n",
      "[1,   600] loss: 0.070 accuracy: 0.766\n",
      "[1,   800] loss: 0.072 accuracy: 0.755\n",
      "[1,  1000] loss: 0.071 accuracy: 0.750\n",
      "[1,  1200] loss: 0.070 accuracy: 0.762\n",
      "[1,  1400] loss: 0.072 accuracy: 0.757\n",
      "[1,  1600] loss: 0.072 accuracy: 0.747\n",
      "[1,  1800] loss: 0.071 accuracy: 0.754\n",
      "[1,  2000] loss: 0.071 accuracy: 0.755\n",
      "[1,  2200] loss: 0.072 accuracy: 0.754\n",
      "[1,  2400] loss: 0.072 accuracy: 0.749\n",
      "[1,  2600] loss: 0.071 accuracy: 0.753\n",
      "[1,  2800] loss: 0.071 accuracy: 0.751\n",
      "[1,  3000] loss: 0.072 accuracy: 0.751\n",
      "[1,  3200] loss: 0.071 accuracy: 0.760\n",
      "[1,  3400] loss: 0.072 accuracy: 0.747\n",
      "[1,  3600] loss: 0.070 accuracy: 0.765\n",
      "[1,  3800] loss: 0.072 accuracy: 0.749\n",
      "[1,  4000] loss: 0.071 accuracy: 0.755\n",
      "[1,  4200] loss: 0.073 accuracy: 0.748\n",
      "[1,  4400] loss: 0.072 accuracy: 0.758\n",
      "[1,  4600] loss: 0.073 accuracy: 0.749\n",
      "[1,  4800] loss: 0.069 accuracy: 0.766\n",
      "[1,  5000] loss: 0.071 accuracy: 0.756\n",
      "[1,  5200] loss: 0.070 accuracy: 0.764\n",
      "[1,  5400] loss: 0.071 accuracy: 0.755\n",
      "[1,  5600] loss: 0.072 accuracy: 0.756\n",
      "[1,  5800] loss: 0.070 accuracy: 0.757\n",
      "[1,  6000] loss: 0.071 accuracy: 0.754\n",
      "[1,  6200] loss: 0.073 accuracy: 0.744\n",
      "[1,  6400] loss: 0.072 accuracy: 0.761\n",
      "[1,  6600] loss: 0.073 accuracy: 0.755\n",
      "[1,  6800] loss: 0.071 accuracy: 0.757\n",
      "[1,  7000] loss: 0.071 accuracy: 0.756\n",
      "[1,  7200] loss: 0.071 accuracy: 0.756\n",
      "[1,  7400] loss: 0.071 accuracy: 0.758\n",
      "[1,  7600] loss: 0.070 accuracy: 0.758\n",
      "[1,  7800] loss: 0.071 accuracy: 0.756\n",
      "[1,  8000] loss: 0.071 accuracy: 0.757\n",
      "[1,  8200] loss: 0.069 accuracy: 0.767\n",
      "[1,  8400] loss: 0.071 accuracy: 0.759\n",
      "[1,  8600] loss: 0.071 accuracy: 0.753\n",
      "[1,  8800] loss: 0.071 accuracy: 0.754\n",
      "[1,  9000] loss: 0.070 accuracy: 0.761\n",
      "[1,  9200] loss: 0.071 accuracy: 0.758\n",
      "[1,  9400] loss: 0.073 accuracy: 0.754\n",
      "[1,  9600] loss: 0.071 accuracy: 0.759\n",
      "[1,  9800] loss: 0.071 accuracy: 0.754\n",
      "[1, 10000] loss: 0.071 accuracy: 0.760\n",
      "[1, 10200] loss: 0.071 accuracy: 0.757\n",
      "[1, 10400] loss: 0.070 accuracy: 0.762\n",
      "[1, 10600] loss: 0.072 accuracy: 0.754\n",
      "[1, 10800] loss: 0.073 accuracy: 0.743\n",
      "[1, 11000] loss: 0.073 accuracy: 0.749\n",
      "[1, 11200] loss: 0.070 accuracy: 0.759\n",
      "[1, 11400] loss: 0.071 accuracy: 0.758\n",
      "[1, 11600] loss: 0.070 accuracy: 0.754\n",
      "[1, 11800] loss: 0.070 accuracy: 0.760\n",
      "[1, 12000] loss: 0.071 accuracy: 0.759\n",
      "[1, 12200] loss: 0.072 accuracy: 0.752\n",
      "[1, 12400] loss: 0.072 accuracy: 0.754\n",
      "[1, 12600] loss: 0.070 accuracy: 0.761\n",
      "[1, 12800] loss: 0.070 accuracy: 0.760\n",
      "[1, 13000] loss: 0.072 accuracy: 0.754\n",
      "[1, 13200] loss: 0.071 accuracy: 0.755\n",
      "[1, 13400] loss: 0.070 accuracy: 0.763\n",
      "[1, 13600] loss: 0.071 accuracy: 0.754\n",
      "[1, 13800] loss: 0.071 accuracy: 0.762\n",
      "[1, 14000] loss: 0.072 accuracy: 0.748\n",
      "[1, 14200] loss: 0.072 accuracy: 0.756\n",
      "[1, 14400] loss: 0.071 accuracy: 0.754\n",
      "[1, 14600] loss: 0.072 accuracy: 0.752\n",
      "[1, 14800] loss: 0.071 accuracy: 0.759\n",
      "[1, 15000] loss: 0.069 accuracy: 0.766\n",
      "[1, 15200] loss: 0.072 accuracy: 0.754\n",
      "[1, 15400] loss: 0.072 accuracy: 0.751\n",
      "[1, 15600] loss: 0.072 accuracy: 0.758\n",
      "[1, 15800] loss: 0.072 accuracy: 0.752\n",
      "[1, 16000] loss: 0.070 accuracy: 0.762\n",
      "[1, 16200] loss: 0.070 accuracy: 0.757\n",
      "[1, 16400] loss: 0.070 accuracy: 0.757\n",
      "[1, 16600] loss: 0.072 accuracy: 0.752\n",
      "[1, 16800] loss: 0.070 accuracy: 0.763\n",
      "[1, 17000] loss: 0.071 accuracy: 0.756\n",
      "[1, 17200] loss: 0.070 accuracy: 0.759\n",
      "[1, 17400] loss: 0.071 accuracy: 0.756\n",
      "[1, 17600] loss: 0.070 accuracy: 0.762\n",
      "[1, 17800] loss: 0.071 accuracy: 0.754\n",
      "[1, 18000] loss: 0.071 accuracy: 0.754\n",
      "[1, 18200] loss: 0.070 accuracy: 0.757\n",
      "[1, 18400] loss: 0.069 accuracy: 0.760\n",
      "[1, 18600] loss: 0.071 accuracy: 0.752\n",
      "[1, 18800] loss: 0.071 accuracy: 0.757\n",
      "[1, 19000] loss: 0.071 accuracy: 0.753\n",
      "[1, 19200] loss: 0.071 accuracy: 0.758\n",
      "[1, 19400] loss: 0.070 accuracy: 0.761\n",
      "[1, 19600] loss: 0.071 accuracy: 0.757\n",
      "[1, 19800] loss: 0.070 accuracy: 0.754\n",
      "[1, 20000] loss: 0.071 accuracy: 0.750\n",
      "[1, 20200] loss: 0.072 accuracy: 0.754\n",
      "[1, 20400] loss: 0.070 accuracy: 0.760\n",
      "[1, 20600] loss: 0.071 accuracy: 0.761\n",
      "[1, 20800] loss: 0.071 accuracy: 0.758\n",
      "[1, 21000] loss: 0.071 accuracy: 0.758\n",
      "[1, 21200] loss: 0.070 accuracy: 0.759\n",
      "[1, 21400] loss: 0.069 accuracy: 0.764\n",
      "[1, 21600] loss: 0.071 accuracy: 0.756\n",
      "[1, 21800] loss: 0.071 accuracy: 0.758\n",
      "[1, 22000] loss: 0.071 accuracy: 0.756\n",
      "[1, 22200] loss: 0.070 accuracy: 0.763\n",
      "[1, 22400] loss: 0.070 accuracy: 0.757\n",
      "[1, 22600] loss: 0.070 accuracy: 0.758\n",
      "[1, 22800] loss: 0.070 accuracy: 0.761\n",
      "[1, 23000] loss: 0.071 accuracy: 0.759\n",
      "[1, 23200] loss: 0.069 accuracy: 0.764\n",
      "[1, 23400] loss: 0.071 accuracy: 0.758\n",
      "[1, 23600] loss: 0.069 accuracy: 0.762\n",
      "[1, 23800] loss: 0.070 accuracy: 0.757\n",
      "[1, 24000] loss: 0.070 accuracy: 0.757\n",
      "[1, 24200] loss: 0.069 accuracy: 0.760\n",
      "[1, 24400] loss: 0.071 accuracy: 0.757\n",
      "[1, 24600] loss: 0.069 accuracy: 0.762\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d60a432e43143b88dbfd03e3ed0c79f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3100.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val acc: 0.7644837668884856\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de6649caa1254a978a30a82d0b0ddede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=24795.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,   200] loss: 0.070 accuracy: 0.761\n",
      "[2,   400] loss: 0.069 accuracy: 0.764\n",
      "[2,   600] loss: 0.070 accuracy: 0.757\n",
      "[2,   800] loss: 0.069 accuracy: 0.760\n",
      "[2,  1000] loss: 0.069 accuracy: 0.765\n",
      "[2,  1200] loss: 0.070 accuracy: 0.762\n",
      "[2,  1400] loss: 0.070 accuracy: 0.761\n",
      "[2,  1600] loss: 0.070 accuracy: 0.762\n",
      "[2,  1800] loss: 0.069 accuracy: 0.765\n",
      "[2,  2000] loss: 0.070 accuracy: 0.761\n",
      "[2,  2200] loss: 0.069 accuracy: 0.763\n",
      "[2,  2400] loss: 0.071 accuracy: 0.754\n",
      "[2,  2600] loss: 0.069 accuracy: 0.765\n",
      "[2,  2800] loss: 0.070 accuracy: 0.763\n",
      "[2,  3000] loss: 0.070 accuracy: 0.765\n",
      "[2,  3200] loss: 0.070 accuracy: 0.763\n",
      "[2,  3400] loss: 0.070 accuracy: 0.764\n",
      "[2,  3600] loss: 0.071 accuracy: 0.759\n",
      "[2,  3800] loss: 0.070 accuracy: 0.760\n",
      "[2,  4000] loss: 0.069 accuracy: 0.760\n",
      "[2,  4200] loss: 0.069 accuracy: 0.766\n",
      "[2,  4400] loss: 0.069 accuracy: 0.766\n",
      "[2,  4600] loss: 0.071 accuracy: 0.757\n",
      "[2,  4800] loss: 0.071 accuracy: 0.755\n",
      "[2,  5000] loss: 0.069 accuracy: 0.762\n",
      "[2,  5200] loss: 0.069 accuracy: 0.759\n",
      "[2,  5400] loss: 0.069 accuracy: 0.761\n",
      "[2,  5600] loss: 0.070 accuracy: 0.759\n",
      "[2,  5800] loss: 0.070 accuracy: 0.762\n",
      "[2,  6000] loss: 0.069 accuracy: 0.766\n",
      "[2,  6200] loss: 0.068 accuracy: 0.766\n",
      "[2,  6400] loss: 0.071 accuracy: 0.756\n",
      "[2,  6600] loss: 0.069 accuracy: 0.762\n",
      "[2,  6800] loss: 0.070 accuracy: 0.761\n",
      "[2,  7000] loss: 0.071 accuracy: 0.756\n",
      "[2,  7200] loss: 0.068 accuracy: 0.764\n",
      "[2,  7400] loss: 0.070 accuracy: 0.761\n",
      "[2,  7600] loss: 0.070 accuracy: 0.760\n",
      "[2,  7800] loss: 0.070 accuracy: 0.761\n",
      "[2,  8000] loss: 0.070 accuracy: 0.761\n",
      "[2,  8200] loss: 0.070 accuracy: 0.758\n",
      "[2,  8400] loss: 0.070 accuracy: 0.763\n",
      "[2,  8600] loss: 0.070 accuracy: 0.760\n",
      "[2,  8800] loss: 0.069 accuracy: 0.763\n",
      "[2,  9200] loss: 0.070 accuracy: 0.756\n",
      "[2,  9400] loss: 0.071 accuracy: 0.754\n",
      "[2,  9600] loss: 0.069 accuracy: 0.757\n",
      "[2,  9800] loss: 0.068 accuracy: 0.770\n",
      "[2, 10000] loss: 0.068 accuracy: 0.765\n",
      "[2, 10200] loss: 0.070 accuracy: 0.762\n",
      "[2, 10400] loss: 0.069 accuracy: 0.763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 14200] loss: 0.069 accuracy: 0.763\n",
      "[2, 14400] loss: 0.071 accuracy: 0.762\n",
      "[2, 14600] loss: 0.070 accuracy: 0.761\n",
      "[2, 14800] loss: 0.071 accuracy: 0.756\n",
      "[2, 15000] loss: 0.072 accuracy: 0.750\n",
      "[2, 15200] loss: 0.070 accuracy: 0.763\n",
      "[2, 15400] loss: 0.070 accuracy: 0.761\n",
      "[2, 15600] loss: 0.070 accuracy: 0.760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 19000] loss: 0.069 accuracy: 0.767\n",
      "[2, 19200] loss: 0.069 accuracy: 0.760\n",
      "[2, 19400] loss: 0.070 accuracy: 0.761\n",
      "[2, 19600] loss: 0.069 accuracy: 0.759\n",
      "[2, 19800] loss: 0.068 accuracy: 0.766\n",
      "[2, 20000] loss: 0.069 accuracy: 0.758\n",
      "[2, 20200] loss: 0.070 accuracy: 0.763\n",
      "[2, 20400] loss: 0.069 accuracy: 0.765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 24000] loss: 0.069 accuracy: 0.759\n",
      "[2, 24200] loss: 0.069 accuracy: 0.762\n",
      "[2, 24400] loss: 0.070 accuracy: 0.760\n",
      "[2, 24600] loss: 0.068 accuracy: 0.770\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11a515c70e264c9fa601d40e56dbf170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3100.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val acc: 0.7624773139745916\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c7574ea02a74931bc9a61a7da426ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=24795.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,   200] loss: 0.070 accuracy: 0.763\n",
      "[3,   400] loss: 0.069 accuracy: 0.763\n",
      "[3,   600] loss: 0.069 accuracy: 0.766\n",
      "[3,   800] loss: 0.069 accuracy: 0.767\n",
      "[3,  1000] loss: 0.069 accuracy: 0.759\n",
      "[3,  1200] loss: 0.067 accuracy: 0.764\n",
      "[3,  1400] loss: 0.069 accuracy: 0.765\n",
      "[3,  1600] loss: 0.070 accuracy: 0.759\n",
      "[3,  1800] loss: 0.069 accuracy: 0.759\n",
      "[3,  2000] loss: 0.068 accuracy: 0.768\n",
      "[3,  2200] loss: 0.067 accuracy: 0.774\n",
      "[3,  2400] loss: 0.069 accuracy: 0.764\n",
      "[3,  2600] loss: 0.070 accuracy: 0.760\n",
      "[3,  2800] loss: 0.069 accuracy: 0.764\n",
      "[3,  3000] loss: 0.069 accuracy: 0.766\n",
      "[3,  3200] loss: 0.069 accuracy: 0.765\n",
      "[3,  3400] loss: 0.069 accuracy: 0.762\n",
      "[3,  3600] loss: 0.069 accuracy: 0.766\n",
      "[3,  3800] loss: 0.069 accuracy: 0.764\n",
      "[3,  4000] loss: 0.068 accuracy: 0.770\n",
      "[3,  4200] loss: 0.069 accuracy: 0.763\n",
      "[3,  4400] loss: 0.068 accuracy: 0.771\n",
      "[3,  4600] loss: 0.069 accuracy: 0.763\n",
      "[3,  4800] loss: 0.069 accuracy: 0.765\n",
      "[3,  5000] loss: 0.069 accuracy: 0.767\n",
      "[3,  5200] loss: 0.068 accuracy: 0.762\n",
      "[3,  5400] loss: 0.067 accuracy: 0.768\n",
      "[3,  5600] loss: 0.069 accuracy: 0.762\n",
      "[3,  5800] loss: 0.067 accuracy: 0.771\n",
      "[3,  6000] loss: 0.069 accuracy: 0.765\n",
      "[3,  6200] loss: 0.067 accuracy: 0.771\n",
      "[3,  6400] loss: 0.069 accuracy: 0.764\n",
      "[3,  6600] loss: 0.069 accuracy: 0.765\n",
      "[3,  6800] loss: 0.069 accuracy: 0.761\n",
      "[3,  7000] loss: 0.068 accuracy: 0.768\n",
      "[3,  7200] loss: 0.070 accuracy: 0.759\n",
      "[3,  7400] loss: 0.069 accuracy: 0.767\n",
      "[3,  7600] loss: 0.067 accuracy: 0.772\n",
      "[3,  7800] loss: 0.068 accuracy: 0.770\n",
      "[3,  8000] loss: 0.068 accuracy: 0.773\n",
      "[3,  8200] loss: 0.068 accuracy: 0.764\n",
      "[3,  8400] loss: 0.069 accuracy: 0.767\n",
      "[3,  8600] loss: 0.068 accuracy: 0.771\n",
      "[3,  8800] loss: 0.069 accuracy: 0.762\n",
      "[3,  9000] loss: 0.067 accuracy: 0.764\n",
      "[3,  9200] loss: 0.069 accuracy: 0.764\n",
      "[3,  9400] loss: 0.067 accuracy: 0.773\n",
      "[3,  9600] loss: 0.069 accuracy: 0.765\n",
      "[3,  9800] loss: 0.069 accuracy: 0.766\n",
      "[3, 10000] loss: 0.068 accuracy: 0.768\n",
      "[3, 10200] loss: 0.068 accuracy: 0.769\n",
      "[3, 10400] loss: 0.068 accuracy: 0.769\n",
      "[3, 10600] loss: 0.068 accuracy: 0.761\n",
      "[3, 10800] loss: 0.068 accuracy: 0.767\n",
      "[3, 11000] loss: 0.068 accuracy: 0.766\n",
      "[3, 11200] loss: 0.069 accuracy: 0.762\n",
      "[3, 11400] loss: 0.067 accuracy: 0.773\n",
      "[3, 11600] loss: 0.068 accuracy: 0.768\n",
      "[3, 11800] loss: 0.069 accuracy: 0.764\n",
      "[3, 12000] loss: 0.069 accuracy: 0.764\n",
      "[3, 12200] loss: 0.070 accuracy: 0.760\n",
      "[3, 12400] loss: 0.068 accuracy: 0.764\n",
      "[3, 12600] loss: 0.069 accuracy: 0.763\n",
      "[3, 12800] loss: 0.069 accuracy: 0.767\n",
      "[3, 13000] loss: 0.068 accuracy: 0.769\n",
      "[3, 13200] loss: 0.067 accuracy: 0.769\n",
      "[3, 13400] loss: 0.067 accuracy: 0.773\n",
      "[3, 13600] loss: 0.070 accuracy: 0.759\n",
      "[3, 13800] loss: 0.067 accuracy: 0.770\n",
      "[3, 14000] loss: 0.069 accuracy: 0.768\n",
      "[3, 14200] loss: 0.069 accuracy: 0.764\n",
      "[3, 14400] loss: 0.069 accuracy: 0.767\n",
      "[3, 14600] loss: 0.070 accuracy: 0.762\n",
      "[3, 14800] loss: 0.069 accuracy: 0.766\n",
      "[3, 15000] loss: 0.067 accuracy: 0.771\n",
      "[3, 15200] loss: 0.068 accuracy: 0.764\n",
      "[3, 15400] loss: 0.068 accuracy: 0.767\n",
      "[3, 15600] loss: 0.069 accuracy: 0.761\n",
      "[3, 15800] loss: 0.068 accuracy: 0.776\n",
      "[3, 16000] loss: 0.069 accuracy: 0.764\n",
      "[3, 16200] loss: 0.069 accuracy: 0.764\n",
      "[3, 16400] loss: 0.068 accuracy: 0.766\n",
      "[3, 16600] loss: 0.068 accuracy: 0.770\n",
      "[3, 16800] loss: 0.069 accuracy: 0.764\n",
      "[3, 17000] loss: 0.068 accuracy: 0.771\n",
      "[3, 17200] loss: 0.069 accuracy: 0.766\n",
      "[3, 17400] loss: 0.069 accuracy: 0.760\n",
      "[3, 17600] loss: 0.068 accuracy: 0.769\n",
      "[3, 17800] loss: 0.070 accuracy: 0.759\n",
      "[3, 18000] loss: 0.068 accuracy: 0.766\n",
      "[3, 18200] loss: 0.069 accuracy: 0.757\n",
      "[3, 18400] loss: 0.069 accuracy: 0.765\n",
      "[3, 18600] loss: 0.068 accuracy: 0.766\n",
      "[3, 18800] loss: 0.069 accuracy: 0.767\n",
      "[3, 19000] loss: 0.067 accuracy: 0.774\n",
      "[3, 19200] loss: 0.069 accuracy: 0.767\n",
      "[3, 19400] loss: 0.068 accuracy: 0.768\n",
      "[3, 19600] loss: 0.069 accuracy: 0.764\n",
      "[3, 19800] loss: 0.067 accuracy: 0.767\n",
      "[3, 20000] loss: 0.067 accuracy: 0.771\n",
      "[3, 20200] loss: 0.069 accuracy: 0.761\n",
      "[3, 20400] loss: 0.069 accuracy: 0.764\n",
      "[3, 20600] loss: 0.069 accuracy: 0.767\n",
      "[3, 20800] loss: 0.068 accuracy: 0.764\n",
      "[3, 21000] loss: 0.069 accuracy: 0.767\n",
      "[3, 21200] loss: 0.067 accuracy: 0.769\n",
      "[3, 21400] loss: 0.067 accuracy: 0.773\n",
      "[3, 21600] loss: 0.068 accuracy: 0.769\n",
      "[3, 21800] loss: 0.069 accuracy: 0.759\n",
      "[3, 22000] loss: 0.067 accuracy: 0.768\n",
      "[3, 22200] loss: 0.068 accuracy: 0.768\n",
      "[3, 22400] loss: 0.068 accuracy: 0.769\n",
      "[3, 22600] loss: 0.068 accuracy: 0.770\n",
      "[3, 22800] loss: 0.068 accuracy: 0.769\n",
      "[3, 23000] loss: 0.069 accuracy: 0.765\n",
      "[3, 23200] loss: 0.067 accuracy: 0.774\n",
      "[3, 23400] loss: 0.069 accuracy: 0.764\n",
      "[3, 23600] loss: 0.068 accuracy: 0.765\n",
      "[3, 23800] loss: 0.070 accuracy: 0.763\n",
      "[3, 24000] loss: 0.069 accuracy: 0.761\n",
      "[3, 24200] loss: 0.068 accuracy: 0.767\n",
      "[3, 24400] loss: 0.069 accuracy: 0.764\n",
      "[3, 24600] loss: 0.069 accuracy: 0.766\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bded5afe1cbf4158be57b36be5dd928c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3100.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val acc: 0.7710980036297641\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77669302e7e4fce8f3774fe633f8273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=24795.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,   200] loss: 0.068 accuracy: 0.764\n",
      "[4,   400] loss: 0.068 accuracy: 0.772\n",
      "[4,   600] loss: 0.068 accuracy: 0.770\n",
      "[4,   800] loss: 0.068 accuracy: 0.764\n",
      "[4,  1000] loss: 0.067 accuracy: 0.775\n",
      "[4,  1200] loss: 0.066 accuracy: 0.776\n",
      "[4,  1400] loss: 0.067 accuracy: 0.771\n",
      "[4,  1600] loss: 0.067 accuracy: 0.770\n",
      "[4,  1800] loss: 0.066 accuracy: 0.768\n",
      "[4,  2000] loss: 0.067 accuracy: 0.774\n",
      "[4,  2200] loss: 0.069 accuracy: 0.767\n",
      "[4,  2400] loss: 0.068 accuracy: 0.765\n",
      "[4,  2600] loss: 0.067 accuracy: 0.771\n",
      "[4,  2800] loss: 0.066 accuracy: 0.776\n",
      "[4,  3000] loss: 0.067 accuracy: 0.775\n",
      "[4,  3200] loss: 0.067 accuracy: 0.772\n",
      "[4,  3400] loss: 0.067 accuracy: 0.769\n",
      "[4,  3600] loss: 0.068 accuracy: 0.762\n",
      "[4,  3800] loss: 0.067 accuracy: 0.769\n",
      "[4,  4000] loss: 0.066 accuracy: 0.777\n",
      "[4,  4200] loss: 0.066 accuracy: 0.772\n",
      "[4,  4400] loss: 0.069 accuracy: 0.765\n",
      "[4,  4600] loss: 0.068 accuracy: 0.763\n",
      "[4,  4800] loss: 0.068 accuracy: 0.770\n",
      "[4,  5000] loss: 0.067 accuracy: 0.772\n",
      "[4,  5200] loss: 0.067 accuracy: 0.768\n",
      "[4,  5400] loss: 0.068 accuracy: 0.767\n",
      "[4,  5600] loss: 0.067 accuracy: 0.771\n",
      "[4,  5800] loss: 0.067 accuracy: 0.777\n",
      "[4,  6000] loss: 0.068 accuracy: 0.762\n",
      "[4,  6200] loss: 0.067 accuracy: 0.772\n",
      "[4,  6400] loss: 0.067 accuracy: 0.771\n",
      "[4,  6600] loss: 0.066 accuracy: 0.775\n",
      "[4,  6800] loss: 0.068 accuracy: 0.765\n",
      "[4,  7000] loss: 0.068 accuracy: 0.769\n",
      "[4,  7200] loss: 0.069 accuracy: 0.764\n",
      "[4,  7400] loss: 0.067 accuracy: 0.771\n",
      "[4,  7600] loss: 0.065 accuracy: 0.777\n",
      "[4,  7800] loss: 0.068 accuracy: 0.769\n",
      "[4,  8000] loss: 0.068 accuracy: 0.768\n",
      "[4,  8200] loss: 0.068 accuracy: 0.771\n",
      "[4,  8400] loss: 0.067 accuracy: 0.769\n",
      "[4,  8600] loss: 0.066 accuracy: 0.776\n",
      "[4,  8800] loss: 0.067 accuracy: 0.769\n",
      "[4,  9000] loss: 0.066 accuracy: 0.774\n",
      "[4,  9200] loss: 0.068 accuracy: 0.770\n",
      "[4,  9400] loss: 0.066 accuracy: 0.772\n",
      "[4,  9600] loss: 0.068 accuracy: 0.762\n",
      "[4,  9800] loss: 0.067 accuracy: 0.772\n",
      "[4, 10000] loss: 0.067 accuracy: 0.770\n",
      "[4, 10200] loss: 0.068 accuracy: 0.769\n",
      "[4, 10400] loss: 0.069 accuracy: 0.764\n",
      "[4, 10600] loss: 0.067 accuracy: 0.769\n",
      "[4, 10800] loss: 0.068 accuracy: 0.767\n",
      "[4, 11000] loss: 0.067 accuracy: 0.771\n",
      "[4, 11200] loss: 0.065 accuracy: 0.781\n",
      "[4, 11400] loss: 0.067 accuracy: 0.770\n",
      "[4, 11600] loss: 0.067 accuracy: 0.773\n",
      "[4, 12200] loss: 0.068 accuracy: 0.767\n",
      "[4, 12400] loss: 0.067 accuracy: 0.764\n",
      "[4, 12600] loss: 0.068 accuracy: 0.765\n",
      "[4, 12800] loss: 0.067 accuracy: 0.769\n",
      "[4, 13000] loss: 0.067 accuracy: 0.773\n",
      "[4, 13200] loss: 0.069 accuracy: 0.764\n",
      "[4, 13400] loss: 0.068 accuracy: 0.769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 17000] loss: 0.067 accuracy: 0.768\n",
      "[4, 17200] loss: 0.069 accuracy: 0.764\n",
      "[4, 17400] loss: 0.067 accuracy: 0.770\n",
      "[4, 17600] loss: 0.067 accuracy: 0.775\n",
      "[4, 17800] loss: 0.068 accuracy: 0.768\n",
      "[4, 18000] loss: 0.067 accuracy: 0.771\n",
      "[4, 18200] loss: 0.066 accuracy: 0.776\n",
      "[4, 18400] loss: 0.069 accuracy: 0.764\n",
      "[4, 18600] loss: 0.068 accuracy: 0.767\n",
      "[4, 18800] loss: 0.069 accuracy: 0.761\n",
      "[4, 19000] loss: 0.067 accuracy: 0.773\n",
      "[4, 19200] loss: 0.068 accuracy: 0.765\n",
      "[4, 19400] loss: 0.068 accuracy: 0.768\n",
      "[4, 19600] loss: 0.067 accuracy: 0.770\n",
      "[4, 19800] loss: 0.066 accuracy: 0.768\n",
      "[4, 20000] loss: 0.069 accuracy: 0.765\n",
      "[4, 20200] loss: 0.068 accuracy: 0.770\n",
      "[4, 20400] loss: 0.069 accuracy: 0.761\n",
      "[4, 20600] loss: 0.068 accuracy: 0.766\n",
      "[4, 20800] loss: 0.066 accuracy: 0.777\n",
      "[4, 21000] loss: 0.067 accuracy: 0.769\n",
      "[4, 21200] loss: 0.067 accuracy: 0.770\n",
      "[4, 21400] loss: 0.068 accuracy: 0.773\n",
      "[4, 21600] loss: 0.065 accuracy: 0.779\n",
      "[4, 21800] loss: 0.067 accuracy: 0.768\n",
      "[4, 22000] loss: 0.068 accuracy: 0.770\n",
      "[4, 22200] loss: 0.068 accuracy: 0.768\n",
      "[4, 22400] loss: 0.068 accuracy: 0.764\n",
      "[4, 22600] loss: 0.067 accuracy: 0.770\n",
      "[4, 22800] loss: 0.068 accuracy: 0.766\n",
      "[4, 23000] loss: 0.067 accuracy: 0.772\n",
      "[4, 23200] loss: 0.066 accuracy: 0.770\n",
      "[4, 23400] loss: 0.068 accuracy: 0.767\n",
      "[4, 23600] loss: 0.066 accuracy: 0.778\n",
      "[4, 23800] loss: 0.067 accuracy: 0.771\n",
      "[4, 24000] loss: 0.067 accuracy: 0.773\n",
      "[4, 24200] loss: 0.068 accuracy: 0.774\n",
      "[4, 24400] loss: 0.068 accuracy: 0.767\n",
      "[4, 24600] loss: 0.066 accuracy: 0.774\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a593bd06fe9e4375a29d9467d6a135d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3100.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val acc: 0.7797035692679976\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "023faae487c04220aed463a03e4a4735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=24795.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,   200] loss: 0.066 accuracy: 0.776\n",
      "[5,   400] loss: 0.065 accuracy: 0.777\n",
      "[5,   600] loss: 0.065 accuracy: 0.778\n",
      "[5,   800] loss: 0.066 accuracy: 0.776\n",
      "[5,  1000] loss: 0.066 accuracy: 0.776\n",
      "[5,  1200] loss: 0.066 accuracy: 0.777\n",
      "[5,  1400] loss: 0.067 accuracy: 0.769\n",
      "[5,  1600] loss: 0.066 accuracy: 0.775\n",
      "[5,  1800] loss: 0.067 accuracy: 0.774\n",
      "[5,  2000] loss: 0.066 accuracy: 0.773\n",
      "[5,  2200] loss: 0.067 accuracy: 0.772\n",
      "[5,  2400] loss: 0.067 accuracy: 0.773\n",
      "[5,  2600] loss: 0.066 accuracy: 0.775\n",
      "[5,  2800] loss: 0.067 accuracy: 0.770\n",
      "[5,  3000] loss: 0.066 accuracy: 0.777\n",
      "[5,  3200] loss: 0.067 accuracy: 0.773\n",
      "[5,  3400] loss: 0.066 accuracy: 0.776\n",
      "[5,  3600] loss: 0.068 accuracy: 0.768\n",
      "[5,  3800] loss: 0.067 accuracy: 0.768\n",
      "[5,  4000] loss: 0.065 accuracy: 0.777\n",
      "[5,  4200] loss: 0.066 accuracy: 0.772\n",
      "[5,  4400] loss: 0.066 accuracy: 0.778\n",
      "[5,  4600] loss: 0.065 accuracy: 0.778\n",
      "[5,  4800] loss: 0.066 accuracy: 0.773\n",
      "[5,  5000] loss: 0.065 accuracy: 0.778\n",
      "[5,  5200] loss: 0.065 accuracy: 0.778\n",
      "[5,  5400] loss: 0.067 accuracy: 0.774\n",
      "[5,  5600] loss: 0.067 accuracy: 0.773\n",
      "[5,  5800] loss: 0.066 accuracy: 0.775\n",
      "[5,  6000] loss: 0.066 accuracy: 0.776\n",
      "[5,  6200] loss: 0.066 accuracy: 0.776\n",
      "[5,  6400] loss: 0.068 accuracy: 0.768\n",
      "[5,  6600] loss: 0.067 accuracy: 0.775\n",
      "[5,  6800] loss: 0.066 accuracy: 0.772\n",
      "[5,  7000] loss: 0.067 accuracy: 0.771\n",
      "[5,  7200] loss: 0.067 accuracy: 0.774\n",
      "[5,  7400] loss: 0.067 accuracy: 0.771\n",
      "[5,  7600] loss: 0.066 accuracy: 0.771\n",
      "[5,  7800] loss: 0.066 accuracy: 0.777\n",
      "[5,  8000] loss: 0.065 accuracy: 0.775\n",
      "[5,  8200] loss: 0.067 accuracy: 0.773\n",
      "[5,  8400] loss: 0.068 accuracy: 0.770\n",
      "[5,  8600] loss: 0.066 accuracy: 0.776\n",
      "[5,  8800] loss: 0.066 accuracy: 0.771\n",
      "[5,  9000] loss: 0.067 accuracy: 0.776\n",
      "[5,  9200] loss: 0.067 accuracy: 0.770\n",
      "[5,  9400] loss: 0.068 accuracy: 0.767\n",
      "[5,  9600] loss: 0.067 accuracy: 0.771\n",
      "[5,  9800] loss: 0.066 accuracy: 0.777\n",
      "[5, 10000] loss: 0.066 accuracy: 0.776\n",
      "[5, 10200] loss: 0.067 accuracy: 0.775\n",
      "[5, 10400] loss: 0.066 accuracy: 0.773\n",
      "[5, 10600] loss: 0.067 accuracy: 0.770\n",
      "[5, 10800] loss: 0.065 accuracy: 0.782\n",
      "[5, 11000] loss: 0.067 accuracy: 0.769\n",
      "[5, 11200] loss: 0.067 accuracy: 0.772\n",
      "[5, 11400] loss: 0.067 accuracy: 0.773\n",
      "[5, 11600] loss: 0.066 accuracy: 0.774\n",
      "[5, 11800] loss: 0.067 accuracy: 0.774\n",
      "[5, 12000] loss: 0.067 accuracy: 0.767\n",
      "[5, 12200] loss: 0.066 accuracy: 0.772\n",
      "[5, 12400] loss: 0.066 accuracy: 0.775\n",
      "[5, 12600] loss: 0.067 accuracy: 0.772\n",
      "[5, 12800] loss: 0.068 accuracy: 0.769\n",
      "[5, 13000] loss: 0.066 accuracy: 0.772\n",
      "[5, 13200] loss: 0.066 accuracy: 0.774\n",
      "[5, 13400] loss: 0.067 accuracy: 0.773\n",
      "[5, 13600] loss: 0.065 accuracy: 0.776\n",
      "[5, 13800] loss: 0.067 accuracy: 0.774\n",
      "[5, 14000] loss: 0.067 accuracy: 0.772\n",
      "[5, 14200] loss: 0.067 accuracy: 0.774\n",
      "[5, 14400] loss: 0.066 accuracy: 0.773\n",
      "[5, 14600] loss: 0.067 accuracy: 0.772\n",
      "[5, 14800] loss: 0.066 accuracy: 0.775\n",
      "[5, 15000] loss: 0.067 accuracy: 0.773\n",
      "[5, 15200] loss: 0.066 accuracy: 0.775\n",
      "[5, 15400] loss: 0.067 accuracy: 0.773\n",
      "[5, 15600] loss: 0.066 accuracy: 0.776\n",
      "[5, 16000] loss: 0.066 accuracy: 0.775\n",
      "[5, 16200] loss: 0.067 accuracy: 0.771\n",
      "[5, 16400] loss: 0.065 accuracy: 0.777\n",
      "[5, 16600] loss: 0.066 accuracy: 0.777\n",
      "[5, 16800] loss: 0.066 accuracy: 0.770\n",
      "[5, 17000] loss: 0.066 accuracy: 0.776\n",
      "[5, 17200] loss: 0.065 accuracy: 0.775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 20600] loss: 0.066 accuracy: 0.776\n",
      "[5, 20800] loss: 0.067 accuracy: 0.772\n",
      "[5, 21000] loss: 0.068 accuracy: 0.763\n",
      "[5, 21200] loss: 0.067 accuracy: 0.771\n",
      "[5, 21400] loss: 0.066 accuracy: 0.771\n",
      "[5, 21600] loss: 0.065 accuracy: 0.776\n",
      "[5, 21800] loss: 0.067 accuracy: 0.771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 24000] loss: 0.066 accuracy: 0.774\n",
      "[5, 24200] loss: 0.065 accuracy: 0.778\n",
      "[5, 24400] loss: 0.067 accuracy: 0.769\n",
      "[5, 24600] loss: 0.067 accuracy: 0.772\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43c1addf3e414db19edf402673f9248e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3100.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val acc: 0.7825065537406736\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aea256874014339ad3e0ed05be46c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=24795.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,   200] loss: 0.065 accuracy: 0.781\n",
      "[6,   400] loss: 0.064 accuracy: 0.783\n",
      "[6,   600] loss: 0.067 accuracy: 0.772\n",
      "[6,   800] loss: 0.063 accuracy: 0.782\n",
      "[6,  1000] loss: 0.066 accuracy: 0.775\n",
      "[6,  1200] loss: 0.067 accuracy: 0.773\n",
      "[6,  1400] loss: 0.065 accuracy: 0.775\n",
      "[6,  1600] loss: 0.066 accuracy: 0.772\n",
      "[6,  1800] loss: 0.066 accuracy: 0.777\n",
      "[6,  2000] loss: 0.065 accuracy: 0.775\n",
      "[6,  2200] loss: 0.066 accuracy: 0.775\n",
      "[6,  2400] loss: 0.066 accuracy: 0.773\n",
      "[6,  2600] loss: 0.065 accuracy: 0.782\n",
      "[6,  2800] loss: 0.065 accuracy: 0.775\n",
      "[6,  3000] loss: 0.064 accuracy: 0.782\n",
      "[6,  3200] loss: 0.066 accuracy: 0.773\n",
      "[6,  3400] loss: 0.065 accuracy: 0.781\n",
      "[6,  3600] loss: 0.067 accuracy: 0.772\n",
      "[6,  3800] loss: 0.066 accuracy: 0.778\n",
      "[6,  4000] loss: 0.066 accuracy: 0.776\n",
      "[6,  4200] loss: 0.066 accuracy: 0.773\n",
      "[6,  4800] loss: 0.065 accuracy: 0.777\n",
      "[6,  5000] loss: 0.064 accuracy: 0.776\n",
      "[6,  5200] loss: 0.066 accuracy: 0.776\n",
      "[6,  5400] loss: 0.066 accuracy: 0.772\n",
      "[6,  5600] loss: 0.065 accuracy: 0.778\n",
      "[6,  5800] loss: 0.065 accuracy: 0.777\n",
      "[6,  6000] loss: 0.065 accuracy: 0.781\n",
      "[6,  6200] loss: 0.064 accuracy: 0.782\n",
      "[6,  6400] loss: 0.066 accuracy: 0.775\n",
      "[6,  6600] loss: 0.065 accuracy: 0.779\n",
      "[6,  6800] loss: 0.065 accuracy: 0.778\n",
      "[6,  7000] loss: 0.065 accuracy: 0.779\n",
      "[6,  7200] loss: 0.066 accuracy: 0.777\n",
      "[6,  7400] loss: 0.066 accuracy: 0.773\n",
      "[6,  7600] loss: 0.065 accuracy: 0.777\n",
      "[6,  7800] loss: 0.064 accuracy: 0.782\n",
      "[6,  8000] loss: 0.066 accuracy: 0.772\n",
      "[6,  8200] loss: 0.063 accuracy: 0.786\n",
      "[6,  8400] loss: 0.065 accuracy: 0.782\n",
      "[6,  8600] loss: 0.065 accuracy: 0.778\n",
      "[6,  8800] loss: 0.067 accuracy: 0.771\n",
      "[6,  9000] loss: 0.065 accuracy: 0.775\n",
      "[6,  9200] loss: 0.066 accuracy: 0.772\n",
      "[6,  9400] loss: 0.065 accuracy: 0.777\n",
      "[6,  9600] loss: 0.065 accuracy: 0.779\n",
      "[6,  9800] loss: 0.066 accuracy: 0.774\n",
      "[6, 10000] loss: 0.065 accuracy: 0.772\n",
      "[6, 10200] loss: 0.065 accuracy: 0.777\n",
      "[6, 10400] loss: 0.066 accuracy: 0.776\n",
      "[6, 10600] loss: 0.066 accuracy: 0.776\n",
      "[6, 10800] loss: 0.066 accuracy: 0.773\n",
      "[6, 11000] loss: 0.066 accuracy: 0.778\n",
      "[6, 11200] loss: 0.066 accuracy: 0.778\n",
      "[6, 11400] loss: 0.068 accuracy: 0.769\n",
      "[6, 11800] loss: 0.066 accuracy: 0.777\n",
      "[6, 12000] loss: 0.065 accuracy: 0.777\n",
      "[6, 12200] loss: 0.066 accuracy: 0.775\n",
      "[6, 12400] loss: 0.063 accuracy: 0.786\n",
      "[6, 12600] loss: 0.065 accuracy: 0.776\n"
     ]
    }
   ],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, pin_memory = True, num_workers = 16)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True, pin_memory = True, num_workers = 16)\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "for epoch in range(64):\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "    for batch_idx, (spec, target) in enumerate(tqdm(trainloader)):\n",
    "        optimizer.zero_grad()\n",
    "        spec, target = spec.float(), target.float()\n",
    "        if half:\n",
    "            spec, target = spec.half(),target.half()\n",
    "        spec = spec.cuda(device)\n",
    "        target = target.cuda(device)\n",
    "\n",
    "        out = overnet(spec)\n",
    "        loss = criterion(out, target)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(overnet.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "                \n",
    "        running_loss += loss.item()\n",
    "        running_accuracy += compute_corrects(out, target)/batch_size\n",
    "        if batch_idx % 200 == 199:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f accuracy: %.3f' % \n",
    "                  (epoch + 1, batch_idx + 1, running_loss / 200, running_accuracy / 200))\n",
    "            running_loss = 0.0\n",
    "            running_accuracy = 0.0\n",
    "            torch.save({\n",
    "            'model_state_dict': overnet.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss\n",
    "            }, 'models/overnet8.pth')\n",
    "\n",
    "        \n",
    "    with torch.no_grad():    \n",
    "        corrects = 0\n",
    "        for batch_idx, (spec, target) in enumerate(tqdm(valloader)):\n",
    "            spec, target = spec.float(), target.float()\n",
    "            if half:\n",
    "                spec, target = spec.half(), target.half()\n",
    "            spec = spec.cuda(device)\n",
    "            target = target.cuda(device)\n",
    "            overnet.eval()\n",
    "            out = overnet(spec) \n",
    "            corrects += compute_corrects(out, target)\n",
    "        print('val acc:', corrects/len(valset))\n",
    "        if corrects/len(valset) > bestacc:\n",
    "            bestacc = corrects/len(valset)\n",
    "            torch.save({\n",
    "            'model_state_dict': overnet.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            'bestacc': bestacc\n",
    "            }, 'models/best-overnet8.pth')\n",
    "        overnet.train()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f4c99cdd22c4a0aa65417d3b9e201b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3100.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test acc: 0.731498285944747\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('models/best-overnet8.pth')\n",
    "overnet.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True, pin_memory = True, num_workers = 16)\n",
    "\n",
    "overnet.eval()\n",
    "corrects = 0\n",
    "for batch_idx, (spec, target) in enumerate(tqdm(testloader)):\n",
    "    spec, target = spec.float(), target.float()\n",
    "    if half:\n",
    "        spec, target = spec.half(), target.half()\n",
    "    spec = spec.cuda(device)\n",
    "    target = target.cuda(device)\n",
    "    out = overnet(spec) \n",
    "    corrects += compute_corrects(out, target)\n",
    "print('test acc:', corrects/len(testset))\n",
    "overnet.train()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
