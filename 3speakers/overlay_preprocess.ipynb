{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "from lxml.html import parse\n",
    "from sphfile import SPHFile\n",
    "import pydub\n",
    "import audiosegment\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "root = '../'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('joie_chen', 5360), ('peter_jennings', 5000), ('lou_waters', 3838), ('linden_soles', 3354), ('leon_harris', 3099), ('david_brancaccio', 2872), ('ted_koppel', 2783), ('natalie_allen', 2750), ('karen_maginnis', 2742), ('brian_lamb', 2590), ('noah_adams', 2018), ('jeanne_meserve', 2009), ('bill_clinton', 1899), ('lynn_vaughan', 1887), ('kathleen_kennedy', 1778), ('thalia_assuras', 1587), ('mark_mullen', 1483), ('byron_miranda', 1477), ('lisa_mullins', 1443), ('csp_waj_susan', 1371)]\n"
     ]
    }
   ],
   "source": [
    "segments_df = pd.read_csv(root+'files/segments.csv')\n",
    "segments_df = segments_df.sample(frac=1, random_state = 12345)\n",
    "\n",
    "speakers = Counter(segments_df['speaker'])\n",
    "common_speakers = speakers.most_common(20)\n",
    "print(common_speakers)\n",
    "#common_speakers = [common_speaker[0] for common_speaker in common_speakers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make train.csv\n",
    "train_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maybe try increasing dataset size by doing each combination of 290*290"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segments_by_speakers = {speaker:segments_df[segments_df['speaker']==speaker][:1271] for speaker in common_speakers}\n",
    "# overlay = []\n",
    "# for first_speaker in common_speakers:\n",
    "#     second_speakers = [speaker for speaker in common_speakers if speaker!=first_speaker ]\n",
    "#     first_segments = segments_by_speakers[first_speaker]\n",
    "#     for second_speaker in second_speakers:\n",
    "#         second_segments = segments_by_speakers[second_speaker]\n",
    "#         first_idx = np.arange(200)\n",
    "#         second_idx = np.arange(200)\n",
    "#         np.random.shuffle(first_idx)\n",
    "#         np.random.shuffle(second_idx)\n",
    "#         for i in range(200):\n",
    "#             first_segment = first_segments.iloc[first_idx[i]]\n",
    "#             second_segment = second_segments.iloc[second_idx[i]]\n",
    "#             row = {'first_speaker': first_speaker, 'second_speaker': second_speaker,\n",
    "#                   'first_file': first_segment['segfile'], 'second_file': second_segment['segfile']}\n",
    "#             overlay.append(row)\n",
    "# overlay = pd.DataFrame(overlay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_shuffled = overlay.sample(frac=1, random_state = 12345)\n",
    "overlay_shuffled.to_csv('overlay-train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_by_speakers = {speaker:segments_df[segments_df['speaker']==speaker][200:246] for speaker in common_speakers}\n",
    "overlay = []\n",
    "for first_speaker in common_speakers:\n",
    "    second_speakers = [speaker for speaker in common_speakers if speaker!=first_speaker ]\n",
    "    first_segments = segments_by_speakers[first_speaker]\n",
    "    for second_speaker in second_speakers:\n",
    "        second_segments = segments_by_speakers[second_speaker]\n",
    "        first_idx = np.arange(46)\n",
    "        second_idx = np.arange(46)\n",
    "        np.random.shuffle(first_idx)\n",
    "        np.random.shuffle(second_idx)\n",
    "        for i in range(46):\n",
    "            first_segment = first_segments.iloc[first_idx[i]]\n",
    "            second_segment = second_segments.iloc[second_idx[i]]\n",
    "            row = {'first_speaker': first_speaker, 'second_speaker': second_speaker,\n",
    "                  'first_file': first_segment['segfile'], 'second_file': second_segment['segfile']}\n",
    "            overlay.append(row)\n",
    "overlay = pd.DataFrame(overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_shuffled = overlay.sample(frac=1, random_state = 12345)\n",
    "overlay_shuffled.to_csv('overlay-val.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_by_speakers = {speaker:segments_df[segments_df['speaker']==speaker][246:292] for speaker in common_speakers}\n",
    "overlay = []\n",
    "for first_speaker in common_speakers:\n",
    "    second_speakers = [speaker for speaker in common_speakers if speaker!=first_speaker ]\n",
    "    first_segments = segments_by_speakers[first_speaker]\n",
    "    for second_speaker in second_speakers:\n",
    "        second_segments = segments_by_speakers[second_speaker]\n",
    "        first_idx = np.arange(46)\n",
    "        second_idx = np.arange(46)\n",
    "        np.random.shuffle(first_idx)\n",
    "        np.random.shuffle(second_idx)\n",
    "        for i in range(46):\n",
    "            first_segment = first_segments.iloc[first_idx[i]]\n",
    "            second_segment = second_segments.iloc[second_idx[i]]\n",
    "            row = {'first_speaker': first_speaker, 'second_speaker': second_speaker,\n",
    "                  'first_file': first_segment['segfile'], 'second_file': second_segment['segfile']}\n",
    "            overlay.append(row)\n",
    "overlay = pd.DataFrame(overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_shuffled = overlay.sample(frac=1, random_state = 12345)\n",
    "overlay_shuffled.to_csv('overlay-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
